# General purpose

```{r setup, message=FALSE,warning=FALSE}
library(glitter)
library(tidyverse)
library(ggpubr)
```

## Aim of the article

This study's objectives are to

1)  collect and assess the information provided by the Wikimedia initiative (Wikidata, Wikipedia, Wikimedia Commons) on flood events.
2)  compare this data, which is crowdsourced, to an institutionnally curated database on the same topic.
3)  use this data to characterize the historical importance and human impact of the flood events documented.

## Digital Humanities Quarterly scope:

Open Access Journal. The journal's scope includes but is not limited to:

-   Digital Tools and Methods in Humanities Research: DHQ publishes articles that showcase **innovative digital tools, methods, and approaches** used in humanities scholarship. This can involve text analysis, data visualization, digital archives, GIS (Geographic Information Systems), network analysis, and more.

-   Critical Assessment of Digital Technologies in Humanities Studies: DHQ features critical evaluations and discussions about the **implications, challenges, and limitations of using digital technologies in humanities research**. This includes considerations of ethics, accessibility, and cultural implications of digital humanities work.

-   Interdisciplinary Collaborations: The journal promotes **interdisciplinary** collaborations by highlighting research at the intersection of humanities disciplines and technology. It covers collaborations between historians, literary scholars, linguists, cultural studies scholars, and experts in computer science, data science, and information technology.

-   Digital Pedagogy and Teaching Approaches: DHQ discusses innovative pedagogical approaches that integrate digital tools and methods into humanities teaching. This includes case studies, reviews, and discussions on the use of technology in the classroom to enhance learning experiences.

-   **Digital Humanities Projects and Case Studies**: The journal publishes case studies and reports on digital humanities projects, initiatives, and experiments, providing insights into the practical application of digital methods in various humanities fields.

-   Open Access and Open Data: DHQ supports open access and open data principles, often discussing issues related to **data curation, preservation, and accessibility in the context of digital humanities research**.

## Intro

@sekajugo_can_2022 explores the interest of citizen science for collecting data about floods, at a regional scale.

# Wikidata on floods

## Basic stats

```{r wd_stats}
wd_events=readRDS("data/wd_events.RDS")
wd_full=readRDS("data/wd_full.RDS")
Nwd=wd_events %>% nrow()
Naft1900=wd_events %>% filter(year>=1900) %>% nrow()
Naft2000=wd_events %>% filter(year>=2000) %>% nrow()
Propaft1900=Naft1900/Nwd
Propaft2000=Naft2000/Nwd
```

Our Wikidata base documents `r Nwd` flood events, `r Propaft1900`% of which occurred after 1900 and `r Propaft2000`% of which occurred after 2000.

```{r wd_years, fig.width=8,fig.height=4}
#| label: fig-wd_year
#| fig-cap: "Distribution of flood events through time A) all events dated with a year-accuracy B) events dated with a year-accuracy starting in 2000"
wd_events_freq=wd_events %>% 
  mutate(cat_year=cut(year,breaks=c(1000,1200,1400,1600,1800,
                                    2000,2023),dig.lab=10)) %>% 
  group_by(cat_year) %>% tally()
p1=ggplot(wd_events_freq, aes(x=cat_year,y=n))+
  geom_col()
p2=ggplot(wd_events %>% filter(year>=2000), aes(x=year))+
  geom_histogram(breaks=2000:2023)
figure <- ggarrange(p1,p2,
                    labels = c("A", "B"),
                    ncol = 1, nrow = 2)
figure
```

## Map

```{r wd_map, warning=FALSE, message=FALSE}
library(leaflet) 
 wd_map=wd_full %>%
  # filter NA coords before transforming in sf multipoint
  filter(!is.na(coords)) %>%
  sf::st_as_sf(wkt="coords") %>% 
  # group by flood event
  group_by(flood,flood_label) %>%
  # in case there is no Wikipedia article 
  mutate(noarticle=all(is.na(article)),
         noimage=all(is.na(image)),
         lang=stringr::str_extract(article,"..(?=\\.wikipedia)"),
         flood=stringr::str_replace(flood,"wd:","")) %>% 
  mutate(article=case_when(noarticle~"",
                           !noarticle~glue::glue("<a href='{article}',target='_blank'>{lang} ðŸ”— </a>")),
         image=case_when(noimage~"",
                         !noimage~glue::glue("<img src='{image}'  width='200'>"))) %>% 
  summarise(coords_from=first(coords_from),
            year=first(year),
            country_label=first(country_label),
            deathtoll=mean(deathtoll,na.rm=TRUE),
            date=first(date),
            start=first(start),
            end=first(end),
            date_precision=first(date_precision),
            article=paste0(unique(article), collapse=" "),
            image=paste0(unique(image),collapse=" ")) %>% 
  ungroup() %>% 
  mutate(popup=glue::glue("<h1>{flood_label}<a href='http://www.wikidata.org/entity/{flood}'
                             target='_blank'>ðŸ”—</a></h1>")) %>%
  mutate(popup=case_when(!is.na(date)~glue::glue("{popup}<p>date: {date}</p>"),
                                 TRUE~popup)) %>% 
  mutate(popup=case_when(!is.na(deathtoll)~glue::glue("{popup}<p>deathtoll:{deathtoll}</p>"),
                                 TRUE~popup)) %>% 
  mutate(popup=case_when(!is.na(article)~glue::glue("{popup}<p>{article}</p>"),
                                 TRUE~popup)) %>% 
  mutate(popup=case_when(!is.na(image)~glue::glue("{popup}<p>{image}</p>"),
                                 TRUE~popup)) %>% 
  sf::st_centroid()
coords=wd_map %>%
  sf::st_coordinates() %>% 
  as_tibble() %>% 
  select(long=X,lat=Y)
wd_map=wd_map %>% 
  bind_cols(coords) %>% 
  mutate(coords_txt=as.character(coords))
```

```{r def_jitter_coords}
jitter_coord=function(datlonlat,n){
  long=datlonlat$long+runif(n,-1,1)
  lat=datlonlat$lat+runif(n,-1,1)
  result=tibble::tibble(flood=datlonlat$flood,
                           long=long,
                           lat=lat)
  return(result)
}
```

```{r jittered_coords}
jittered_coords=wd_map  %>% 
  sf::st_drop_geometry() %>% 
  select(flood,coords_txt,long,lat) %>% 
  unique() %>% 
  group_by(coords_txt) %>%
  mutate(n=n()) %>%
  tidyr::nest(data=c(flood,long,lat)) %>%
  mutate(data=purrr::map2(data,n,jitter_coord)) %>%
  tidyr::unnest(data) %>%
  ungroup()

```

```{r}
wd_map=wd_map %>%
  sf::st_drop_geometry() %>% 
  select(-long,-lat,-coords_txt) %>% 
  left_join(jittered_coords %>%
              select(flood,long,lat),
            by="flood") %>% 
  sf::st_as_sf(coords = c("long", "lat"), 
               crs = 4326, agr = "constant")
```


```{r}
# DÃ©finition d'une Ã©chelle colorÃ©e 
# (en fonction de date de sortie) 
pal <- colorNumeric(c("red", "green", "blue"),
                    c(1648,1900,1950,1980,2000,2010,2023)) 
# CrÃ©ation de la carte 
leaf_wd_map=leaflet(wd_map) %>% # dÃ©f carte 
  addProviderTiles(providers$Esri.NatGeoWorldMap) %>% # ajout fond de carte
  addCircleMarkers(col=~pal(year),
                   popup = ~popup,
                   radius =~log(deathtoll+2)
                   ) 

```

```{r leaf_wd_map, fig.width=10,fig.height=8}
leaf_wd_map 
```

# Data from institutionnally curated databases

## Data from the Dartmouth Flood Observatory

```{r def_avdate}
avdate=function(date1,date2){
  date1=as.numeric(date1)
  date2=as.numeric(date2)
  result=as.Date(mean(c(date1,date2)))
  return(result)
}
```

```{r read_tib_dfo, warning=FALSE, message=FALSE}
dfo_raw <- readr::read_csv("data/FloodArchive.csv", 
    locale = locale(decimal_mark = ","))
colnames(dfo_raw)=c("index","GlideNumber","dfo_country","dfo_other_country",
           "dfo_centroid_x","dfo_centroid_y","area","dfo_began","dfo_ended",
           "validation","dfo_dead","displaced","maincause","severity")
dfo_raw=dfo_raw %>% 
  mutate(start=lubridate::dmy(dfo_began),
         end=lubridate::dmy(dfo_ended)) %>% 
  mutate(dfo_other_country=case_when(is.na(dfo_other_country)~"",
                                     dfo_other_country==0~"",
                                     TRUE~dfo_other_country)) %>% 
  mutate(flood=as.character(index),
         flood_label=as.character(index),
         country_label=paste(dfo_country," ",dfo_other_country),
         deathtoll=dfo_dead,
         coords=paste0("Point(",dfo_centroid_x," ",dfo_centroid_y,")"))
dfo_comp=dfo_raw %>% 
  select(flood,flood_label,country_label,deathtoll, start, end,coords) %>% 
  mutate(date=purrr::map2(start,end,avdate)) %>% 
  tidyr::unnest(date)
```

```{r}
coords_wd_map=sf::st_coordinates(wd_map) %>%
  as_tibble() %>%
  mutate(coords=glue::glue("Point({X} {Y})")) %>%
  pull(coords)
wd_comp=wd_map %>%
  sf::st_drop_geometry() %>% 
  mutate(coords=coords_wd_map) %>% 
  select(flood,flood_label,country_label,deathtoll, date ,start, end,coords,popup) %>% 
  mutate(flood=stringr::str_replace(flood,"wd:",""))
```

This dataset documents `r nrow(dfo_comp)` flood events that occurred between `r min(dfo_comp$start)` and `r max(dfo_comp$end)`.

```{r}
Nwd_in_range=wd_events %>% 
  filter(year>=1985 & year<=2021) %>% 
  sf::st_drop_geometry() %>%
  summarise(n=length(unique(flood))) %>% 
  pull(n)
```

Based on the dates of observations for the dfo data base, `r Nwd_in_range` out of the `r Nwd` flood events in our Wikidata base might fall into it.

## Basic stats

```{r}
wd_comp=wd_comp  %>% 
   mutate(source="wd") %>% 
   mutate(flood=paste0("wd:",flood)) %>% 
   sf::st_drop_geometry() %>% 
   filter(date>lubridate::ymd("1985-01-01") & 
          date<lubridate::ymd("2021-12-31")) 
dfo_comp=dfo_comp %>%
   mutate(source="dfo") %>%
   mutate(popup=glue::glue("<h1>{flood_label}</h1>
                            <p>date: {date}</p>
                            <p>deathtoll:{deathtoll}</p>"))  
tib=bind_rows(wd_comp,dfo_comp) %>% 
  mutate(date=lubridate::round_date(date,"month")) %>% 
   sf::st_as_sf(wkt="coords")
```

Try and find correspondences

```{r def_find_corresponding_flood}
find_corresponding_flood=function(flood_id,tib){
  tib_sub=tib %>% filter(flood==flood_id)
  tib_dist=tib %>% 
    mutate(disttime=abs(tib$date-tib_sub$date),
           distspace=sf::st_distance(tib,tib_sub)[,1]) %>% 
    filter(flood!=flood_id) %>%  
    filter(disttime==min(disttime)|distspace==min(distspace)) %>% 
    filter(disttime<60 & distspace<2) %>%
    select(floodcorr=flood,
           disttime,
           distspace,
           sourcecorr=source,
           country_corr=country_label,
           deathtoll_corr=deathtoll) %>% 
    sf::st_drop_geometry()
  if(nrow(tib_dist)==0){
    tib_dist=tibble::tibble(floodcorr=NA,
                            disttime=NA,
                            distspace=NA,
                            sourcecorr=NA,
                            countrycorr=NA,
                            deathtollcorr=NA)
  }
  return(tib_dist)
}
```

```{r}
if(!file.exists("data/tibcorr.RDS")){
tibcorr= tib %>% 
  mutate(data=purrr::map(flood,find_corresponding_flood,tib=tib)) %>% 
  tidyr::unnest(data) %>% 
  filter(source=="wd" & sourcecorr=="dfo")
saveRDS(tibcorr,
        "data/tibcorr.RDS")
}
```

```{r}
tib=sf::st_as_sf(tib,wkt="coords")
tibcorr=readRDS("data/tibcorr.RDS") %>% 
  sf::st_drop_geometry()
truc=bind_rows(tibble::tibble(id=1:nrow(tibcorr),flood=tibcorr$flood),
               tibble::tibble(id=1:nrow(tibcorr),flood=tibcorr$floodcorr))
truc=tib %>% 
  left_join(truc, by="flood") %>%  
  select(id,flood) %>% 
  group_by(id) %>% 
  summarise(m =mean(id),do_union=FALSE) %>% 
  sf::st_cast("LINESTRING")
truc=truc[1:(nrow(truc)-1),]
```

## Map comparison

```{r}
library(leaflet) 
tib_comp_map=tib %>%
  sf::st_as_sf(wkt="coords")
# DÃ©finition d'une Ã©chelle colorÃ©e 
# (en fonction de date de sortie) 
# CrÃ©ation de la carte 
pal=colorFactor(c("red","blue"), domain=c("wd","dfo"))
comp_map=leaflet(tib_comp_map)  %>%
  addProviderTiles(providers$Esri.NatGeoWorldMap) %>% # ajout fond de carte
  addCircleMarkers(col=~pal(source),
                   popup =~popup,
                   radius =~log(deathtoll+2)
                   )  %>%
  addPolylines(data=truc,color="green")
  

```

```{r}
comp_map
```
