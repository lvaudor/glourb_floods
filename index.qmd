# General purpose

```{r setup, message=FALSE,warning=FALSE}
library(glitter)
library(tidyverse)
library(ggpubr)
```

## Aim of the article

This study's objectives are to

1)  collect and assess the information provided by the Wikimedia initiative (Wikidata, Wikipedia, Wikimedia Commons) on flood events.
2)  compare this data, which is crowdsourced, to an institutionnally curated database on the same topic.
3)  use this data to characterize the historical importance and human impact of the flood events documented.

## Digital Humanities Quarterly scope:

Open Access Journal. The journal's scope includes but is not limited to:

-   Digital Tools and Methods in Humanities Research: DHQ publishes articles that showcase **innovative digital tools, methods, and approaches** used in humanities scholarship. This can involve text analysis, data visualization, digital archives, GIS (Geographic Information Systems), network analysis, and more.

-   Critical Assessment of Digital Technologies in Humanities Studies: DHQ features critical evaluations and discussions about the **implications, challenges, and limitations of using digital technologies in humanities research**. This includes considerations of ethics, accessibility, and cultural implications of digital humanities work.

-   Interdisciplinary Collaborations: The journal promotes **interdisciplinary** collaborations by highlighting research at the intersection of humanities disciplines and technology. It covers collaborations between historians, literary scholars, linguists, cultural studies scholars, and experts in computer science, data science, and information technology.

-   Digital Pedagogy and Teaching Approaches: DHQ discusses innovative pedagogical approaches that integrate digital tools and methods into humanities teaching. This includes case studies, reviews, and discussions on the use of technology in the classroom to enhance learning experiences.

-   **Digital Humanities Projects and Case Studies**: The journal publishes case studies and reports on digital humanities projects, initiatives, and experiments, providing insights into the practical application of digital methods in various humanities fields.

-   Open Access and Open Data: DHQ supports open access and open data principles, often discussing issues related to **data curation, preservation, and accessibility in the context of digital humanities research**.

# Introduction

Producing worldwide data about flood events poses numerous challenges due to the complexity of data semantics, collection, standardization, and accessibility. One primary obstacle is the lack of uniform reporting standards across countries and regions, leading to inconsistencies in data collection methods and definitions of flood events. Additionally, varying technological capabilities and resources among nations contribute to disparities in data availability. Natural disasters like floods might occur in areas where communication and infrastructure are limited, hindering real-time data collection. Political, social, and economic factors also play a role, as some regions may under-report or inadequately document flood occurrences due to reasons such as insufficient resources, lack of governmental transparency, or competing priorities. Despite advancements in satellite technology and remote sensing, ensuring comprehensive, accurate, and up-to-date global flood data remains a persistent challenge that requires huge collaborative efforts, data curating, and improved global information-sharing mechanisms.

## Participatory local data about floods

Participatory data collection holds significant potential in enhancing the understanding and management of flood events. This approach involves engaging local communities, citizens, and grassroots organizations in the collection, analysis, and sharing of data related to flood occurrences. Examples of such initiatives show the potential of participatory data to complement institutional data about floods at a local scale [@dixon_role_2021, @sekajugo_can_2022]. By incorporating local knowledge, experiences, and observations, participatory methods complement traditional data sources, offering valuable insights into flood-prone areas that might be overlooked by centralized or remote monitoring systems. More broadly, volunteered geographical data at a local scale has been shown to be a valuable source of data regarding natural hazards.

Communities living in flood-prone regions possess unique, context-specific knowledge about local environmental changes, historical flood patterns, vulnerable areas, and coping mechanisms. Engaging these communities in data collection through citizen science initiatives, mobile applications, community mapping, or participatory workshops allows for the collection of granular, real-time information that supplements existing datasets. This bottom-up approach not only enhances the accuracy and granularity of flood data but also fosters community empowerment, resilience-building, and local capacity development.

Moreover, participatory data can bridge gaps in official reporting by capturing small-scale or localized flood events that might not meet the threshold for formal reporting. Integrating participatory data with conventional datasets enables a more comprehensive understanding of flood dynamics, aiding in the development of effective early warning systems, disaster response plans, and mitigation strategies.

However, challenges such as ensuring data accuracy, reliability, and standardization persist in participatory approaches. Establishing protocols for data validation, quality control, and harmonization between participatory and formal datasets is crucial to maximize the potential of participatory data while maintaining data integrity [@senaratne_review_2017]. The stakes around data validation and homogeneization are particularly high in the prospect of studying floods at a large (or even global) scale.

Overall, leveraging participatory data in conjunction with conventional methods has the potential to enrich global flood databases, improve resilience, and empower communities to better respond to and mitigate the impacts of flood events. This collaborative approach can contribute significantly to more holistic and inclusive strategies for managing floods worldwide.

## Institutional global data about floods

The Dartmouth Flood Observatory (DFO) is a research group specializing in the collection and analysis of global flood data. Combining remote sensing and news reports' analysis, the DFO produces detailed information on the extent, frequency, and impacts of floods worldwide [@kundzewicz_large_2013]. It constitutes an invaluable source of information on the subject, used in many scientific studies on flood events.

In parallel to that kind of research-related, expert database on the subject, the Wikimedia project stands as a remarkable source of structured or semi-structured participatory data with its vast array of user-generated content across platforms like Wikipedia, Wikidata, and Wikimedia Commons. Wikipedia, being one of the largest collaborative encyclopedias globally, harnesses the collective knowledge of volunteers worldwide who contribute, edit, and curate articles on diverse subjects, including geographical features, history, and environmental events such as floods. Wikidata, an open database, provides structured data that can be used to categorize and link information, potentially cataloging flood events, affected regions, and relevant details. Wikimedia Commons serves as a repository for multimedia files, housing images, maps, and other visual resources related to floods, contributing to a more comprehensive understanding of such events. The open nature of Wikimedia projects allows for continual updates and contributions, making it a valuable resource for researchers, policymakers, and the public seeking semi-structured participatory data on various topics, including flood events, across the globe.

# Methods

The methods are detailed (for now) in the other pages of this document.

## Primary census of flood events

We collect Wikidata about floods, using the glitter R package (an API-client to the Wikidata SPARQL endpoint API) [@vaudor_glitter_2023].

## Description of events

We complete the database regarding flood events with attributes corresponding to

- location
- country
- coordinates
- deathtoll
- related Wikipedia articles
- linked images

## Comparison to an institutional database

We compare this data to the DFO database, trying to establish a link between events described on both datasets, based on distance and time gap.


# Results

## Wikidata on floods

```{r wd_stats}
wd_events=readRDS("data/wd_events.RDS")
wd_full=readRDS("data/wd_full.RDS")
Nwd=wd_events %>% nrow()
Naft1900=wd_events %>% filter(year>=1900) %>% nrow()
Naft2000=wd_events %>% filter(year>=2000) %>% nrow()
Propaft1900=Naft1900/Nwd
Propaft2000=Naft2000/Nwd
```

Our Wikidata base documents `r Nwd` flood events, `r Propaft1900`% of which occurred after 1900 and `r Propaft2000`% of which occurred after 2000.

```{r wd_years, fig.width=8,fig.height=4}
#| label: fig-wd_year
#| fig-cap: "Distribution of flood events through time A) all events dated with a year-accuracy B) events dated with a year-accuracy starting in 2000"
wd_events_freq=wd_events %>% 
  mutate(cat_year=cut(year,breaks=c(1000,1200,1400,1600,1800,
                                    2000,2023),dig.lab=10)) %>% 
  group_by(cat_year) %>% tally()
p1=ggplot(wd_events_freq, aes(x=cat_year,y=n))+
  geom_col()
p2=ggplot(wd_events %>% filter(year>=2000), aes(x=year))+
  geom_histogram(breaks=2000:2023)
figure <- ggarrange(p1,p2,
                    labels = c("A", "B"),
                    ncol = 1, nrow = 2)
figure
```

## Compare to DFO data

# Discussion

This study demonstrates the possibility to list and collect information on flood events on a large temporal and spatial scale through Wikidata, Wikimedia and Wikipedia projects. Although these data exhibit some heterogeneity [@lorini_uneven_2020,@ruprechter_poor_2023] due to economic and digital inequities, being able to rely on a preexistent, rich global dataset spanning a large time period is still a priceless asset in studying floods, and could be a first step to better-quality curated datasets. Besides, large-scale institutional data sources themselves are not immune to spatial heterogeneities due to scarcity of research activity in some areas, linguistic barriers, varying degrees of public investment in disaster management, or other sources of environmental, political and social inequities.

Linked Open Data such as Wikidata hold immense interest for the study of natural or social events due to their inherent ability to offer contextual information to documented items. The interconnected nature of Wikidata's model (as a knowledge graph) as well as their link to other data silos indeed allow users to easily access additional information or related resources linked to a particular event. The present study hence demonstrates the strength of such a data source to provide context (in particular through the integration of Wikipedia discourse elements and Wikimedia Commons images) as well as the difficulties inherent to identifying particular flood events based solely on presumably objective information, such as coordinates and dates for these events.

