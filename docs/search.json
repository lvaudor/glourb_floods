[
  {
    "objectID": "4_text_analysis.html",
    "href": "4_text_analysis.html",
    "title": "Text analysis",
    "section": "",
    "text": "library(tidyverse)\nlibrary(stm)\nlibrary(tidytext)\nwd_raw=readRDS(\"data/wd_raw.RDS\")\nwp_words=readRDS(\"data/wp_words.RDS\") %&gt;% \n  filter(flood %in% wd_raw$flood)\n\n\nwp_words_freq=wp_words %&gt;%\n  group_by(lemma) %&gt;% \n  tally() %&gt;% \n  arrange(desc(n)) %&gt;% \n  slice_max(n,n=30)\n\nggplot(wp_words_freq,aes(x=forcats::fct_reorder(lemma,n),\n                         y=n) )+\n  geom_col()+\n  coord_flip()+\n  labs(x=\"lemma\",y=\"frequency\")\n\n\n\n\n\ntib_sparse=wp_words %&gt;% \n  group_by(lemma) %&gt;% # compte pour chaque lemme...\n  mutate(n=n()) %&gt;% # ...son nombre d'occurrences puis\n  filter(n&gt;20) %&gt;%  # retire ceux représentés moins de 20 fois dans le corpus\n  ungroup() %&gt;% \n  cast_sparse(row=flood, column=lemma, value=n)\n\n\nif(!file.exists(\"data/topic_model.RDS\")){\nset.seed(123)\ntopic_model&lt;-stm(tib_sparse,K=6, verbose=FALSE)\nsaveRDS(topic_model,\"data/topic_model.RDS\")\n}\ntopic_model=readRDS(\"data/topic_model.RDS\")\n\n\ntermes_thematiques=tidy(topic_model, matrix=\"beta\") %&gt;% \n  group_by(topic) %&gt;% \n  slice_max(beta,n=30) %&gt;%  \n  mutate(rank=row_number()) %&gt;% \n  arrange(topic,desc(beta)) %&gt;% \n  ungroup()\ntermes_thematiques\n\n# A tibble: 180 × 4\n   topic term       beta  rank\n   &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n 1     1 area     0.0149     1\n 2     1 rain     0.0146     2\n 3     1 cause    0.0145     3\n 4     1 heavy    0.0138     4\n 5     1 rainfall 0.0131     5\n 6     1 record   0.0129     6\n 7     1 water    0.0129     7\n 8     1 damage   0.0125     8\n 9     1 occur    0.0117     9\n10     1 hour     0.0114    10\n# ℹ 170 more rows\n\n\n\ntopics=tibble::tribble(~topic,~topic_label,\n                       1,\"1) spatial range\",\n                       2,\"2) weather\",\n                       3,\"3) hydrology\",\n                       4,\"4) management\",\n                       5,\"5) historical importance\",\n                       6,\"6) human toll\")\n\ntermes_thematiques=termes_thematiques %&gt;% \n  left_join(topics,by=\"topic\")\nsaveRDS(termes_thematiques,\"data/termes_thematiques.RDS\")\n\n\ntib_gamma &lt;- tidy(topic_model, matrix = \"gamma\") %&gt;% \n  left_join(wp_words %&gt;%\n              group_by(flood) %&gt;%\n              summarise(nwords=n()) %&gt;%\n              mutate(document=1:n()),by=\"document\") %&gt;% \n  arrange(flood,desc(gamma)) %&gt;% \n  left_join(topics,by=\"topic\")\nsaveRDS(tib_gamma,\"data/tib_gamma.RDS\")\n\n\n\n\nwp_texts=wp_words %&gt;% group_by(flood,flood_label) %&gt;% summarise(text=str_c(lemma,collapse=\" \"),.groups=\"drop\")\ntemp=textProcessor(documents=wp_texts$text,\n                   metadata=wp_texts %&gt;% select(-text))\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\nout &lt;- prepDocuments(temp$documents, temp$vocab, temp$meta)\n\nRemoving 2396 of 8271 terms (2396 of 183240 tokens) due to frequency \nYour corpus now has 712 documents, 5875 terms and 180844 tokens.\n\n\n\nif(!file.exists(\"data/kresult.RDS\")){\n  documents &lt;- out$documents\n  vocab &lt;- out$vocab\n  meta &lt;- out$meta\n  set.seed(02138)\n  K&lt;-c(3:8)\n  kresult &lt;- searchK(documents, vocab, K, data=meta)\n  saveRDS(kresult,\"data/kresult.RDS\")\n\n}\nkresult=readRDS(\"data/kresult.RDS\")\nplot(kresult)\n\n\n\n\n\n\n\n\nwm_full=readRDS(\"data/wm_full.RDS\") %&gt;% \n  filter(flood %in% wd_raw$flood)\nwp_words2=wp_words %&gt;% \n  left_join(wm_full %&gt;% select(flood,date,country_label),by=\"flood\") %&gt;% \n  mutate(year=lubridate::year(date)) %&gt;% \n  mutate(recent=year&gt;2000) %&gt;% \n  mutate(age=case_when(recent~\"recent\",\n                          !recent~\"old\"))\n\nWarning in left_join(., wm_full %&gt;% select(flood, date, country_label), : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 17402 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nlibrary(mixr)\ntib_spec &lt;- tidy_specificities(wp_words2,cat1=lemma, cat2=country_label, min_spec=2)\nhead(tib_spec)\n\n# A tibble: 6 × 4\n  lemma      country_label  spec     n\n  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;\n1 avert      Austria         Inf  1242\n2 gauge      Austria         Inf  1457\n3 manner     Austria         Inf  1242\n4 ore        Austria         Inf  1377\n5 vote       Austria         Inf  1242\n6 accelerate Belgium         Inf  1056"
  },
  {
    "objectID": "4_text_analysis.html#choice-of-number-of-classes",
    "href": "4_text_analysis.html#choice-of-number-of-classes",
    "title": "Text analysis",
    "section": "",
    "text": "wp_texts=wp_words %&gt;% group_by(flood,flood_label) %&gt;% summarise(text=str_c(lemma,collapse=\" \"),.groups=\"drop\")\ntemp=textProcessor(documents=wp_texts$text,\n                   metadata=wp_texts %&gt;% select(-text))\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\nout &lt;- prepDocuments(temp$documents, temp$vocab, temp$meta)\n\nRemoving 2396 of 8271 terms (2396 of 183240 tokens) due to frequency \nYour corpus now has 712 documents, 5875 terms and 180844 tokens.\n\n\n\nif(!file.exists(\"data/kresult.RDS\")){\n  documents &lt;- out$documents\n  vocab &lt;- out$vocab\n  meta &lt;- out$meta\n  set.seed(02138)\n  K&lt;-c(3:8)\n  kresult &lt;- searchK(documents, vocab, K, data=meta)\n  saveRDS(kresult,\"data/kresult.RDS\")\n\n}\nkresult=readRDS(\"data/kresult.RDS\")\nplot(kresult)"
  },
  {
    "objectID": "4_text_analysis.html#specificities",
    "href": "4_text_analysis.html#specificities",
    "title": "Text analysis",
    "section": "",
    "text": "wm_full=readRDS(\"data/wm_full.RDS\") %&gt;% \n  filter(flood %in% wd_raw$flood)\nwp_words2=wp_words %&gt;% \n  left_join(wm_full %&gt;% select(flood,date,country_label),by=\"flood\") %&gt;% \n  mutate(year=lubridate::year(date)) %&gt;% \n  mutate(recent=year&gt;2000) %&gt;% \n  mutate(age=case_when(recent~\"recent\",\n                          !recent~\"old\"))\n\nWarning in left_join(., wm_full %&gt;% select(flood, date, country_label), : Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 17402 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nlibrary(mixr)\ntib_spec &lt;- tidy_specificities(wp_words2,cat1=lemma, cat2=country_label, min_spec=2)\nhead(tib_spec)\n\n# A tibble: 6 × 4\n  lemma      country_label  spec     n\n  &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;\n1 avert      Austria         Inf  1242\n2 gauge      Austria         Inf  1457\n3 manner     Austria         Inf  1242\n4 ore        Austria         Inf  1377\n5 vote       Austria         Inf  1242\n6 accelerate Belgium         Inf  1056"
  },
  {
    "objectID": "5_join_data.html",
    "href": "5_join_data.html",
    "title": "Wikidata Map",
    "section": "",
    "text": "wm_map corresponds to a dataset with one row=one event (we summarise coordinates into a single centroid) and a popup variable.\nWe will jitter the coordinates in order to not have exactly overlapping coordinates on the map.\nRe-generate data geometry from jittered coords"
  },
  {
    "objectID": "5_join_data.html#data-from-the-dartmouth-flood-observatory",
    "href": "5_join_data.html#data-from-the-dartmouth-flood-observatory",
    "title": "Wikidata Map",
    "section": "Data from the Dartmouth Flood Observatory",
    "text": "Data from the Dartmouth Flood Observatory\nThis dataset documents 5129 flood events that occurred between 1985-01-01 and 2021-10-09."
  },
  {
    "objectID": "5_join_data.html#basic-stats",
    "href": "5_join_data.html#basic-stats",
    "title": "Wikidata Map",
    "section": "Basic stats",
    "text": "Basic stats\nBased on the spatial and temporal data in both datasets, we try to find correspondences between the events described in Wikidata and those described in the Dartmouth Flood Observatory.\nFor each flood event defined in the WD dataset, we filter the DFO dataset to only keep the event corresponding to the minimum distance in space and time, then we consider the events concur if they occurred less than 400 days apart and 400 kms away. This is a rather loose correspondence which is explained by the sometimes low precision in the WD information corresponding to time or coordinates of occurrence (not to mention the inherent difficulty, for contributors of both datasets, of associating a flood event to a precise time and place).\nWe create lines to join events from one dataset to the other."
  },
  {
    "objectID": "5_join_data.html#number-of-correspondences",
    "href": "5_join_data.html#number-of-correspondences",
    "title": "Wikidata Map",
    "section": "Number of correspondences",
    "text": "Number of correspondences\nBased on the dates of observations for the DFO data base, 414 out of the 1048 flood events in our Wikidata base might fall into it.\nOut of 387 flood events documented in the WD comparison data subset, 296 have at least one correspondence in the DFO comparison data subset (76.49%).\nOut of 5129 flood events documented in the DFO comparison data subset, 281 have at least one correspondence in the WD comparison data subset (5.48%)."
  },
  {
    "objectID": "5_join_data.html#why-are-flood-events-documented-in-wikidata",
    "href": "5_join_data.html#why-are-flood-events-documented-in-wikidata",
    "title": "Wikidata Map",
    "section": "Why are flood events documented in Wikidata",
    "text": "Why are flood events documented in Wikidata\n1st hypothesis: number of dead explains the occurrence of the event in WD. =&gt; nope, actually it’s the opposite because events are documented in rich countries in which the number of dead is lower. How to account for this effect?\n\n\n[1] 1.242495\n\n\n[1] 1.492883\n\n\n[1] 134.199\n\n\n[1] 102.089\n\n\n\n\n[1] 134.2184"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site gathers elements regarding flood events documented both through participatory data (Wikidata, Wikipedia) and physical (remote sensing) assessment. It questions the link between these data and what we can infer from them, in particular regarding the impact of floods on humans."
  },
  {
    "objectID": "about.html#digital-humanities-quarterly-scope",
    "href": "about.html#digital-humanities-quarterly-scope",
    "title": "About",
    "section": "Digital Humanities Quarterly scope:",
    "text": "Digital Humanities Quarterly scope:\nOpen Access Journal. The journal’s scope includes but is not limited to:\n\nDigital Tools and Methods in Humanities Research: DHQ publishes articles that showcase innovative digital tools, methods, and approaches used in humanities scholarship. This can involve text analysis, data visualization, digital archives, GIS (Geographic Information Systems), network analysis, and more.\nCritical Assessment of Digital Technologies in Humanities Studies: DHQ features critical evaluations and discussions about the implications, challenges, and limitations of using digital technologies in humanities research. This includes considerations of ethics, accessibility, and cultural implications of digital humanities work.\nInterdisciplinary Collaborations: The journal promotes interdisciplinary collaborations by highlighting research at the intersection of humanities disciplines and technology. It covers collaborations between historians, literary scholars, linguists, cultural studies scholars, and experts in computer science, data science, and information technology.\nDigital Pedagogy and Teaching Approaches: DHQ discusses innovative pedagogical approaches that integrate digital tools and methods into humanities teaching. This includes case studies, reviews, and discussions on the use of technology in the classroom to enhance learning experiences.\nDigital Humanities Projects and Case Studies: The journal publishes case studies and reports on digital humanities projects, initiatives, and experiments, providing insights into the practical application of digital methods in various humanities fields.\nOpen Access and Open Data: DHQ supports open access and open data principles, often discussing issues related to data curation, preservation, and accessibility in the context of digital humanities research."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Online reports and narrations of flood events",
    "section": "",
    "text": "Code\nlibrary(glitter)\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(tidytext)\nlibrary(leaflet)\nlibrary(rainette)\noptions(scipen = 9999)\nwd_events=readRDS(\"data/wd_events.RDS\")\nwm_full=readRDS(\"data/wm_full.RDS\")\nwp_20_words_per_event=readRDS(\"data/wp_20_words_per_event.RDS\")\nwm_full=wm_full %&gt;% \n  left_join(wp_20_words_per_event, by=c(\"flood\"))\ndfo_comp=readRDS(\"data/dfo_comp.RDS\")\nwm_comp=readRDS(\"data/wm_comp.RDS\")\nwm_dfo=readRDS(\"data/wm_dfo.RDS\")\nwm_dfo_corr=readRDS(\"data/wm_dfo_corr.RDS\")"
  },
  {
    "objectID": "index.html#text-analysis-of-wikipedia-pages",
    "href": "index.html#text-analysis-of-wikipedia-pages",
    "title": "Online reports and narrations of flood events",
    "section": "Text analysis of Wikipedia pages",
    "text": "Text analysis of Wikipedia pages\nWe scraped the text (all the textual content in headers from level one (h1) to level 6 (h6) as well as paragraphs) from all listed Wikipedia pages, using the rvest R package (Wickham 2024). We then translated them to English (if necessary) through Google Translate using the polyglotr R package (Iwan 2024).\nWe tokenized the texts with the tidytext R package (Silge and Robinson 2016), lemmatized words and filtered out stop words based on the Iramuteq English dictionnary (Ratinaud 2009). We could then identify textual specificities based on various partitions of the corpus (Lafon, Pierre 1980; Loiseau et al. 2022).\nWe used Reinert’s method (Reinert 1990) to classify segments of our corpus (consisting in successive parts of the Wikipedia articles, segmented in such a way that each contains 10 lemmatized, content words). To implement that method, we used the rainette package (Barnier 2023) and used its exploration tools to choose a meaningful and tractable number of classes. Each class is characterized as a collection of over-represented words, and we used them to label each class in a one-worded, synthetic way. We then used these labelled classes to examine the relationship between the flood characteristics and the topic contents of articles."
  },
  {
    "objectID": "index.html#online-app",
    "href": "index.html#online-app",
    "title": "Online reports and narrations of flood events",
    "section": "Online app",
    "text": "Online app\nThe results and tables can be consulted here:\nlink to app\nThe app provides maps and plots regarding all events (i.e. at the global scale) but also displays, for each event in the database, all the raw data included in the analyses."
  },
  {
    "objectID": "index.html#datasets",
    "href": "index.html#datasets",
    "title": "Online reports and narrations of flood events",
    "section": "Datasets",
    "text": "Datasets\nJe ne suis pas sûre qu’il faille inclure cette partie dans l’article, mais en même temps je trouve qu’il faudrait réussir à correctement valoriser les données elles-mêmes car ce n’était pas une mince affaire de les rassembler…\nWe have gathered and curated tables of data from both Wikidata and Wikipedia :\n\nwd_event: one row = one flood event\nwp_pages: one row = one Wikipedia page\nwp_revisions : one row = one revision of a Wikipedia page\nwp_views: one row = one day of views of a Wikipedia page\nwp_segments: one row = one segment of a Wikipedia page\ncountries: one row = one country * one language\n\nFor each of these tables, we show below the descriptors names, display which among these correspond to a key useable for joining to other tables, the type of data (numeric, character, logical, etc.) and the contents of one row randomly selected.\n\nwd_events\n\n\n\n\n\nvar\nkey\nclass\nn_distinct\nexample\n\n\n\n\nflood\n*\ncharacter\n792\nwd:Q15833333\n\n\nflood_label\n\ncharacter\n698\nThe Magdalen flood of 1480\n\n\ndate\n\nDate\n615\n1480-06-22\n\n\ncountry\n\ncharacter\n154\nNA\n\n\ncountry_label\n\ncharacter\n154\nNA\n\n\ndeathtoll\n\nnumeric\n120\nNA\n\n\nyear\n\nnumeric\n236\n1480\n\n\n\n\n\n\n\nwp_pages\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nkey\nclass\nn_distinct\nexample\n\n\n\n\nflood\n\ncharacter\n727\nwd:Q524797\n\n\narticle\n*\ncharacter\n2630\nhttps://uk.wikipedia.org/wiki/%D0%9F%D0%BE%D0%B2%D1%96%D0%B4%D1%8C_%D0%A1%D0%B2%D1%8F%D1%82%D0%BE%D1%97_%D0%84%D0%BB%D0%B8%D0%B7%D0%B0%D0%B2%D0%B5%D1%82%D0%B8_(1421)\n\n\nlang\n\ncharacter\n122\nuk\n\n\ntitle\n\ncharacter\n2544\nПовідь Святої Єлизавети (1421)\n\n\ntranslated_title\n\ncharacter\n2067\nLeash of Saint Elizabeth (1421)\n\n\ntext\n\ncharacter\n2614\nПовідь Святої Єлизавети (нід. Sint-Elisabethsvloed, 18 листопада — 19 листопада 1421 року; також Дру… [truncated]\n\n\ntextt\n\ncharacter\n2447\nSt. Elizabeth’s Leash (n. Sint-Elisabethsvloed, 18 November – 19 November 1421; also Second St. Eliz… [truncated]\n\n\nlength\n\nnumeric\n1999\n1483\n\n\nlocal\n\nlogical\n2\nFALSE\n\n\n\n\n\n\n\nwp_revisions\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nkey\nclass\nn_distinct\nexample\n\n\n\n\narticle\n*\ncharacter\n2790\nhttps://eu.wikipedia.org/wiki/2010eko_Pakistango_uholdeak\n\n\nid\n\ninteger\n195484\n1688053\n\n\ntimestamp\n\ncharacter\n192838\n2010-09-03T06:02:23Z\n\n\nminor\n\nlogical\n3\nTRUE\n\n\nsize\n\ninteger\n61689\n3619\n\n\ncomment\n\ncharacter\n94509\nrobota Erantsia: [[fa:سیل پاکستان (۲۰۱۰)]]\n\n\ndelta\n\ninteger\n7182\n40\n\n\nuser_id\n\ninteger\n25752\n15795\n\n\nuser_name\n\ncharacter\n44109\nEmausBot\n\n\n\n\n\n\n\nwp_views\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nkey\nclass\nn_distinct\nexample\n\n\n\n\narticle\n*\ncharacter\n2630\nhttps://th.wikipedia.org/wiki/%E0%B8%AD%E0%B8%B8%E0%B8%97%E0%B8%81%E0%B8%A0%E0%B8%B1%E0%B8%A2%E0%B9%83%E0%B8%99%E0%B8%A3%E0%B8%B1%E0%B8%90%E0%B9%80%E0%B8%81%E0%B8%A3%E0%B8%A5%E0%B8%B0_%E0%B8%9E.%E0%B8%A8._2561\n\n\ntitle\n\ncharacter\n2544\nอุทกภัยในรัฐเกรละ พ.ศ. 2561\n\n\nlang\n\ncharacter\n122\nth\n\n\ntimestamp\n\ncharacter\n3138\n2022070100\n\n\nviews\n\ninteger\n3939\n3\n\n\n\n\n\n\n\nwp_segments\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nkey\nclass\nn_distinct\nexample\n\n\n\n\narticle\n*\ncharacter\n2630\nhttps://de.wikipedia.org/wiki/Februarflut_1825\n\n\ntext_all\n\ncharacter\n64198\ndike on the ostland which was not yet connected to the western part of the island broke so that the entire agricultural area there was flooded on juist there were also large dune\n\n\ntext_sig\n\ncharacter\n64147\ndike connect western part island break entire area large dune\n\n\nclass\n\nfactor\n7\nclass_4\n\n\nclass_name\n\nfactor\n7\nhydrology\n\n\ncolor\n\ncharacter\n7\n#76B7B2\n\n\n\n\n\n\n\ncountries\n\n\n\n\n\nvar\nkey\nclass\nn_distinct\nexample\n\n\n\n\ncountry\n*\ncharacter\n110\nwd:Q29\n\n\ncountry_label\n*\ncharacter\n110\nSpain\n\n\ncoords_country\n\ncharacter\n110\nPoint(-3.5 40.2)\n\n\nHDI\n\nnumeric\n101\n0.905\n\n\nlang_type\n\ncharacter\n2\nused\n\n\nlanguage\n\ncharacter\n442\nBasque\n\n\nlanguage_code\n\ncharacter\n441\neu"
  },
  {
    "objectID": "index.html#wikidata-on-floods",
    "href": "index.html#wikidata-on-floods",
    "title": "Online reports and narrations of flood events",
    "section": "Wikidata on floods",
    "text": "Wikidata on floods\nThe initial query provided 1048 Wikidata flood events. In terms of spatial precision, most coordinates are inferred from either variable country or variable location (the major part of provided locations being countries too). The date of most events is documented either directly or through the label of the event. Most events’ dates are provided with day precision but an important proportion (about one third) is provided with only annual precision.\n\n\n\n\n\ncoords_from\nis_country\nn\n\n\n\n\n1) direct\n\n11\n\n\n2) location\nno\n189\n\n\n2) location\nyes\n495\n\n\n3) country\n\n17\n\n\n4) no coordinates\n\n86\n\n\n\n\n\n\n\n\ndate_from\ndate_precision\nn\n\n\n\n\nav_start_end\nday\n145\n\n\ndirect\nday\n224\n\n\ndirect\nmonth\n122\n\n\ndirect\nyear\n107\n\n\nflood_label\nyear\n138\n\n\nstart\nday\n45\n\n\nNA\nNA\n31"
  },
  {
    "objectID": "index.html#wikipedia-on-floods",
    "href": "index.html#wikipedia-on-floods",
    "title": "Online reports and narrations of flood events",
    "section": "Wikipedia on floods",
    "text": "Wikipedia on floods\nThere are 2630 Wikipedia pages associated to these events (i.e. on average 2.58 Wikipedia pages per event). 727 flood events are associated to at least one Wikipedia page.\n455 Wikipedia pages are in English. Out of the 2175 remaining pages, we could translate most pages to English, except 175 pages which were in languages that Google Translate did not support. We based all subsequent textometric analyses on the texts in English, either natively so or translated.\nThe average length of articles (in English or translated to English) is 4348 characters. The 10% shortest articles represent less than 448 characters and the 10% longest ones are more than 9362 characters long.\nThere are 216245 revisions that produced the Wikipedia pages as they appear to this date, which represents an average 82 revisions per page. 175107 (80.98%) of these revisions appear to have been done by human editors and not bots (Wikipedia usernames do not contain the strings “bot” or “Bot”). There are 44109 distinct editors, 40101 (90.91%) of which appear to be humans. On average, each human editor in our corpus is responsible for 4.37 edits. The number of articles (in the corpus) edited by each human editor is distributed as follows:\n\n\n\n\n\nnumber_of_articles_edited\nnumber_of_editors\nproportion_of_editors\n\n\n\n\n(0,1]\n27372\n68.26\n\n\n(1,2]\n8396\n20.94\n\n\n(2,5]\n2976\n7.42\n\n\n(5,10]\n862\n2.15\n\n\n(10,100]\n487\n1.21\n\n\n(100,400]\n8\n0.02"
  },
  {
    "objectID": "index.html#compare-to-dfo-data",
    "href": "index.html#compare-to-dfo-data",
    "title": "Online reports and narrations of flood events",
    "section": "Compare to DFO data",
    "text": "Compare to DFO data\nWe could expect the WD dataset to include less events than the DFO dataset which records flood events primarily based on physical criteria, while one can argue that events are only recorded in WD when they reach some level of social or historical significance. We also expected the WD dataset to be somewhat biased towards events in countries with a higher HDI, as crowdsourced web datasets are known to be. We hence compared the number of events in both datasets according to the HDI class of the country where the event took place.\nWe compare the number of events in both datasets (WD and DFO) according to Human Development Index of the country where the event took place.\n\n\n\n\n\nFigure 2: a) Number of flood events documented in Wikidata (wd), DFO (dfo) or both datasets according to our matching algorithm. The number of events is displayed according to the Human Development Index (HDI) class of the country where the event took place (countries are pooled in the first, second, third or fourth quartile). b) Deathtoll per event according to HDI class and occurrence in one or both datasets. The estimate considered for deathtoll comes either from the DFO dataset, or by default from the Wikidata dataset (some events are not associated to any deathtoll estimate, in which case they are excluded from this figure). Some events happened in places where the country name changed through time making it difficult to link them to a HDI value: these are the ones represented by a NA (not available) HDI class.\n\n\n\n\nFigure 2 .a confirms that compared to DFO, the proportion of events in Wikidata corresponding to countries with higher HDI is important. On the other hand, the distribution of events in the DFO dataset through HDI categories is also quite heterogeneous, with countries in the first and especially second quartile for HDI representing most events. An unbiased distribution of events (when defined through purely physical criteria) should reflect the total area of countries in the four quartiles for HDI, if there were no distinction between them in terms of distribution of more-or-less flood-prone bioms, which we know is not the case). Moreover, even if events are primarily detected based on physical criteria, the DFO dataset still incorporates societal elements (regarding damage and deathtoll for instance) to account for the actual importance or significance of the event. This highlights the systematic difficulty of defining, detecting and reporting flood events in an unbiased, homogeneous way across projects.\nFigure 2 .b shows that compared to DFO-documented events, events included in the WD dataset are generally associated with higher deathtoll. For DFO-documented events, the lower the HDI class, the higher the deathtoll, which could be explained by impoverished countries having less resources and infrastructure to mitigate and respond to such disasters effectively, as well as more inadequate housing and settlement in vulnerable areas exacerbating the impact of floods on communities. As for WD-documented events, the few ones which occurred in lowest HDI countries also correspond to (very) high deathtolls indeed, but so do the ones which have occurred in the richest countries and even more so the ones for which we do not have a value for HDI. In this last case, the events documented in Wikidata only are often historical ones like the 1931 China floods (wd:Q1150973). These floods occurred in the Republic of China (1912-1949), for which we failed to obtain an HDI value, and which were associated with very high and somewhat discussed deathtolls. This highlights the fact that the WD dataset is biased towards events with high societal impact, which is not surprising given the nature of the project.\nAs for the events for which we were able to find a possible match between the WD dataset and the DFO dataset, we can compare the deathtoll values. We can see that the deathtoll values are generally higher in the WD dataset than in the DFO dataset, which is consistent with the fact that the WD dataset is biased towards events with high societal impact. However, the correlation between the deathtoll values in the two datasets is quite high, which suggests that the WD dataset is not completely biased towards events with high deathtoll values, and that there is some overlap between the two datasets.\n\n\n\n\n\nFigure 3: a) Distribution of deathtolls estimates in Wikidata and DFO according to the estimates being paired or not (deathtoll estimates are paired when the events in Wikidata have been paired to an event in DFO). b) Comparison of deathtoll paired estimates in Wikidata and DFO for the same events. The symbol varies according to the deathtoll estimate in Wikidata being sourced, indicating a higher reliability of the estimate."
  },
  {
    "objectID": "index.html#wikipedia-content",
    "href": "index.html#wikipedia-content",
    "title": "Online reports and narrations of flood events",
    "section": "Wikipedia content",
    "text": "Wikipedia content\n\n\n\n\n\nFigure 3: Time delay (in years) between events and revisions to the Wikipedia articles documenting them. The delay might be negative (the edits about an event began before the recorded, average date for the event, hinting to an event with long duration or event with a low-precision recorded date). The color indicates the precision of the recorded event date (it can be accurate to the day, month or year).\n\n\n\n\nFigure 3 shows that most of the writing of Wikipedia articles related to flood events take place during the month of their occurrence (except of course when Wikipedia did not exist (before 2001) or when it was still moderately used to document current events. This highlights the fact that Wikipedia articles about recent flood events can be viewed as news rather than encyclopedic reports on past events. Conversely, one can argue that articles exhibiting a large proportion of revisions implemented a long time after the occurrence of the event could be indicative of an ongoing debate or controversy, or be the ongoing focus of some social or human interest. Notez que je ne l’ai pas fait pour l’instant car je croule déjà sous les données, mais il serait possible (et pas trop compliqué) de récupérer les statistiques de consultation de chacune des pages (et donc de considérer l’intérêt porté à un article du point de vue du lecteur plutôt que du point de vue du créateur de contenu…). Est-ce que vous pensez que je dois me lancer là-dedans?\n\n\n\n\n\nFigure 4: Topics identified by the Reinert classification method. Based on the over-represented terms in each cluster we propose the following labelling of the classes: ‘governance’ for cluster1, ‘relief’ for cluster2, ‘damage’ for cluster3, ‘hydrology’ for cluster4, ‘anticipation’ for cluster5, and ‘weather’ for cluster6.\n\n\n\n\n\n\n\n\n\nFigure 5: Link between total article’s length and topics identified by the Reinert classification method. The articles are classified into 4 categories according to their lengths k (number of segments used for the Reinert classification and identification of topics). The 25% shortest articles represent 1&lt;k&lt;=4 segments while the 25% longest represent 26&lt;k&lt;860 segments. The proportion of segments falling into each category is calculated and the distribution of these proportions is displayed through boxplots for each article length category. The red dots correspond to the median proportions of topics throughout all articles irrespective of articles’ length.\n\n\n\n\nFigure 5 shows that the length of the article is probably a very important factor in the topics addressed (or conversely, the topics addressed determine the length of the article), with shorter articles corresponding to factual statements regarding physical features of the event (weather), and justifying reporting that event based on its consequences (damage), while longer articles might convey more extensive reports on the physical causes (hydrology) and management of the crisis (anticipation, governance, relief).\n\n\n\n\n\nFigure 6: Length of articles as a function of number of revisions.\n\n\n\n\nFigure 6 shows that beyond a few edits (here, we consider the threshold is 10), there is a linear correlation between number of revisions and length of the article (both on a log-scale). The articles in language “simple” (for “simple English”) are by nature destined to be particularly synthetic, so that our model’s parameters are different for them. We finally consider that the difference between observed length and length predicted based on number of edits to represent a certain synthesis or deficit in length.\n\n\n\n\n\nFigure 7: Relationship between age of the Wikipedia page (in days) and deficit in length.\n\n\n\n\nFigure 7 shows that older pages tend to correspond to a more important deficit in length: there is a tendency towards more synthesis as the page ‘matures’. We consider the residuals of this relationship as a way to quantify how synthetic the page currently is (independently of the age factor). We argue that this could be used as a measure of a certain struggle in the establishment of the current text and could thus be interpreted as a sign of possible controversy or debate in its writing process. OK là je ne sais pas quoi faire de cette mesure, j’ai besoin d’aide dans son interprétation pour savoir si on peu effectivement en faire quelque chose pour identifier des événements “hot”"
  },
  {
    "objectID": "2_use_wikipedia.html",
    "href": "2_use_wikipedia.html",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "We translate all Wikipedia pages’ titles and texts to English (when Google translate allows it).\nWe define a translate function, based on the polyglotr package."
  },
  {
    "objectID": "2_use_wikipedia.html#is-language-local",
    "href": "2_use_wikipedia.html#is-language-local",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "is_language_local=function(lang_id,data){\n  result=countries %&gt;% \n    filter(country %in% data$country) %&gt;% \n    filter(lang_id==language_code)\n  result=case_when(nrow(result)&gt;=1~TRUE,\n                   nrow(result)==0~FALSE)\n  return(result)\n}\n\ncountries=readRDS(\"data/countries.RDS\") %&gt;% \n  select(country,language_code) %&gt;% \n  unique()\nwp_pages=readRDS(\"data/wp_pages.RDS\") %&gt;% \n  unique()\nif(!(\"local\" %in% colnames(wp_pages))){\n    wd_events=readRDS(\"data/wd_events.RDS\") \n    wp_pages_local_articles=wd_events %&gt;% select(flood,country) %&gt;% \n      group_by(flood) %&gt;% \n      tidyr::nest() %&gt;% \n      left_join(wp_pages %&gt;% select(flood,article,lang),\n                by=\"flood\",relationship=\"many-to-many\") %&gt;% \n      mutate(local=purrr::map2_lgl(lang,data,is_language_local)) %&gt;% \n      select(article,local)\n    wp_pages=wp_pages %&gt;% \n      left_join(wp_pages_local_articles,by=c(\"flood\",\"article\"))\n    saveRDS(wp_pages,\"data/wp_pages.RDS\")\n}"
  },
  {
    "objectID": "2_use_wikipedia.html#clean-text",
    "href": "2_use_wikipedia.html#clean-text",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "clean_banners=function(text){\n  banner=str_detect(text,\"This article|this banner|your knowledge\")\n  if(banner & !is.na(text)){\n  result=text %&gt;% \n    str_replace(\"This article is.*\\\\n\",\"\") %&gt;% \n    str_replace(\"This article is a draft concerning.*\\\\.\\\\n\\\\n\",\"\") %&gt;% \n    str_replace(\"\\\\nedit - edit code - edit Wikidata\\\\n\",\"\") %&gt;% \n    str_replace(\"You can share your knowledge by.*\\\\.\",\"\") %&gt;% \n    str_replace(\"This article is based.*$\",\"\") %&gt;% \n    str_replace(\"^(.|\\\\n)*If you think these points have been resolved, you can remove this banner and improve the formatting of another article\\\\.\",\"\")%&gt;% \n    str_replace(\"This .*article.*\\\\. You can help Wikipedia by expanding it\\\\.\",\"\") %&gt;% \n    str_replace(\"\\\\..*\\\\}\",\"\")\n  }else{result=text}\n  return(result)\n}\n\n\nif(!file.exists(\"data/wikisites_text.RDS\")){\n  library(rvest)\n  # Get text paragraphs from all Wikipedia articles\n\n  get_text=function(html){\n    html_nodes(html,\"h1, h2, h3, h4, h5, h6, p\") %&gt;%\n    purrr::map(html_text) %&gt;% \n    stringr::str_replace(\"\\\\[.*\\\\]$\",\"\")\n  }\n  wikisites_text=wikisites %&gt;%\n    mutate(html=purrr::map(article,read_html)) %&gt;% \n    mutate(text=purrr::map(html,safely(get_text))) %&gt;% \n    mutate(text=purrr::map(text,\"result\")) %&gt;% \n    select(-html) %&gt;% \n    mutate(text=purrr::map(text,~paste0(.x,collapse=\"\\n\"))) \n\n  \n  # Translate them all to English with Google Translate (if possible)\n  wikisites_textt=wikisites_text %&gt;% \n    mutate(textt=NA)\n  tmp=Sys.time()\n  for(i in 1:nrow(wikisites_textt)){\n    print(i)\n    result=translate(i)\n    if(length(result)&gt;0){\n    wikisites_textt$textt[i]=result}\n  }  \n  print(Sys.time()-tmp) \nsaveRDS(wikisites_textt,\"data/wp_pages_new.RDS\")\n\n  wp_pages=wikisites_textt %&gt;% \n    mutate(textt=purrr::map_chr(textt,clean_banners)) %&gt;% \n    mutate(textt=stringr::str_replace(textt,\"mw-parser-output.*$\",\"\")) %&gt;% \n    mutate(length=map_dbl(textt,str_length)) %&gt;% \n    select(-flood_label)\n  saveRDS(wp_pages,\"data/wp_pages_new.RDS\")\n  \n##FAIT JUSTE AVANT VACANCES =&gt; wp_pages_new.RDS\n}\n\n\n\nwp_pages=readRDS(\"data/wp_pages.RDS\")"
  },
  {
    "objectID": "2_use_wikipedia.html#wp_words",
    "href": "2_use_wikipedia.html#wp_words",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "if(!file.exists(\"data/wp_words.RDS\")){\n  library(mixr)\n  lexicon_en=get_lexicon(\"en\")\n  wp_words=wp_pages %&gt;%\n    tidytext::unnest_tokens(output=\"word\",input=\"textt\",token=\"words\") %&gt;%\n    left_join(lexicon_en,by=c(\"word\")) %&gt;%\n    filter(type!=\"sw\" & lemma!=\"flood\") %&gt;%\n    group_by(flood,lemma) %&gt;%\n    summarise(n=n(),.groups=\"drop\") %&gt;%\n    arrange(flood,desc(n)) \n\nwp_words_spec &lt;- mixr::tidy_specificities(wp_words %&gt;% filter(n&gt;3),lemma, flood) %&gt;% \n  filter(spec&gt;2) %&gt;% \n  group_by(flood) %&gt;% \n  summarise(specific_words=paste(lemma,collapse=\"; \"),.groups=\"drop\")\nsaveRDS(wp_words_spec,\"data/wp_words_spec.RDS\")\nsaveRDS(wp_words,\"data/wp_words.RDS\")\nwp_20_words_per_event=wp_words %&gt;% \n  group_by(flood) %&gt;% \n  arrange(desc(n)) %&gt;% \n  slice_head(n=20) %&gt;% \n  summarise(words=paste(lemma,collapse=\"; \"), .groups=\"drop\")\nsaveRDS(wp_20_words_per_event,\"data/wp_20_words_per_event.RDS\")\n}\nwp_words=readRDS(\"data/wp_words.RDS\") %&gt;% \n  filter(flood %in% wd_raw$flood)"
  },
  {
    "objectID": "2_use_wikipedia.html#classification-of-segments-topics",
    "href": "2_use_wikipedia.html#classification-of-segments-topics",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "if(!file.exists(\"data/wp_segments.RDS\")){\n  library(quanteda)\n  library(rainette)\n  library(mixr)\n    lexicon_en=get_lexicon(\"en\")\n    wp_segments=readRDS(\"data/wp_pages.RDS\") %&gt;%\n    tidytext::unnest_tokens(output=\"word\",input=\"textt\",token=\"words\") %&gt;%\n    left_join(lexicon_en,by=c(\"word\")) %&gt;%\n    mutate(keep=(type!=\"sw\" & lemma!=\"flood\")) %&gt;% \n    group_by(flood,flood_label,article) %&gt;%\n    mutate(lemma=case_when(is.na(lemma)|(!keep)~\"\",\n                           TRUE~lemma)) %&gt;% \n    mutate(keep=as.numeric(keep)) %&gt;% \n    mutate(num_lemma=case_when(is.na(keep)~0,\n                     TRUE~keep)) %&gt;% \n    mutate(num_lemma=cumsum(num_lemma)) %&gt;% \n    mutate(num_segment=ceiling(num_lemma/10+0.000001)) %&gt;% \n    ungroup() %&gt;% \n    group_by(flood,flood_label,article,num_segment) %&gt;% \n    summarise(text_all=paste0(word, collapse=\" \"),\n              text_sig=paste0(lemma,collapse=\" \"),\n              .groups=\"drop\") %&gt;% \n    mutate(num_segment=paste0(article,\"_\",num_segment)) %&gt;% \n    mutate(text_sig_dontkeep=text_sig)\n\n  corpus=corpus(wp_segments,docid_field=\"num_segment\",text_field=\"text_sig_dontkeep\")\n  tok &lt;- tokens(corpus, remove_punct = TRUE, remove_numbers = TRUE)\n  dtm &lt;- dfm(tok)\n  dtm &lt;- dfm_trim(dtm, min_docfreq = 30)\n  set.seed(123)\n  res=rainette(dtm,k=10,min_split_members=10)\n  saveRDS(res,\"data/res_rainette_wp.RDS\")\n  saveRDS(corpus,\"data/corpus.RDS\")\n  saveRDS(dtm,\"data/dtm.RDS\")\n}\nres=readRDS(\"data/res_rainette_wp.RDS\")\ncorpus=readRDS(\"data/corpus.RDS\")\ndtm=readRDS(\"data/dtm.RDS\")\n#rainette_explor(res,dtm,corpus)\n\n\nrainette_plot(\n  res, dtm, k = 6,\n  n_terms = 20,\n  free_scales = TRUE,\n  measure = \"chi2\",\n  show_negative = FALSE,\n  text_size = 12\n)\n\n\n\n\n\nif(!file.exists(\"data/wp_segments.RDS\")){\n  corpus$class=paste0(\"class_\",cutree_rainette(res, k = 6))\n  \n  tib_classes=tibble::tribble(~class,~class_name,~color,\n                  \"class_1\",\"governance\",\"#4E79A7\",\n                  \"class_2\",\"relief\",\"#F28E2B\",\n                  \"class_3\",\"damage\",\"#E15759\",\n                  \"class_4\",\"hydrology\", \"#76B7B2\", \n                  \"class_5\",\"anticipation\",\"#59A14F\",\n                  \"class_6\",\"weather\",\"#EDC948\")\n  wp_segments=docvars(corpus) %&gt;% \n    left_join(tib_classes,by=\"class\") %&gt;% \n    mutate(class=as.factor(class),\n           class_name=as.factor(class_name)) %&gt;% \n    select(-flood,-flood_label)\n  saveRDS(wp_segments,\"data/wp_segments.RDS\")\n}"
  },
  {
    "objectID": "2_use_wikipedia.html#add-classif-results-summary-to-wp_pages",
    "href": "2_use_wikipedia.html#add-classif-results-summary-to-wp_pages",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "wp_segments=readRDS(\"data/wp_segments.RDS\")\nwp_segments_summary=wp_segments %&gt;% \n  group_by(article,class,class_name,color) %&gt;% \n  tally()\nspec=mixr::tidy_specificities(wp_segments,\n                              article,\n                              class_name)\nwp_pages_class=wp_pages %&gt;% \n  left_join(wp_segments_summary,\n            by=\"article\") %&gt;% \n  left_join(spec,by=c(\"article\",\"class_name\",\"n\"))\n\nsaveRDS(wp_pages_class,\"data/wp_pages_class.RDS\")"
  },
  {
    "objectID": "2_use_wikipedia.html#search-for-deathtoll-in-text",
    "href": "2_use_wikipedia.html#search-for-deathtoll-in-text",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "# dat %&gt;% \n#   mutate(mentions_death=stringr::str_detect(text_all,\"dead|death|decease\")) %&gt;% \n#   filter(mentions_death) %&gt;%"
  },
  {
    "objectID": "2_use_wikipedia.html#wp_revisions",
    "href": "2_use_wikipedia.html#wp_revisions",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "source(\"scripts/get_revs.R\")\n\n\nif(!file.exists(\"data/wp_revisions.RDS\")){\nlibrary(httr)\nwp_revisions=wp_pages %&gt;% \n  select(-text,-textt) %&gt;% \n  mutate(revisions=purrr::map2(lang,title,get_revs)) %&gt;% \n  tidyr::unnest(cols=c(revisions)) %&gt;% \n  select(-flood,-flood_label,-lang,-title,-translated_title)\nsaveRDS(wp_revisions,\"data/wp_revisions.RDS\")\n}"
  },
  {
    "objectID": "3_curate_wikidata.html",
    "href": "3_curate_wikidata.html",
    "title": "Curate wikidata",
    "section": "",
    "text": "We query the Wikidata Triplestore through the {glitter} R package (ref).\nHere are the initial results we get when performing this query:\n\n\n\n\n\nwhat\nflood\nloc\ndeathtoll\ncountry\ncountry_label\nflood_label\nwhat_label\ncoords\n\n\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q6886\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q7788\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q15175\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q19206\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q43934\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q45208\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q6401352\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q6886\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q7788\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q15175\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q19206\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q43934\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q45208\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q6401352\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q119109771\nwd:Q790\n51\nwd:Q790\nHaiti\n2023 Haiti floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q122311510\nwd:Q10388860\n47\nwd:Q155\nBrazil\n2023 Rio Grande do Sul floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q1599758\nwd:Q183\n16\nwd:Q183\nGermany\nflood disaster\nnatural disaster\nPoint(9.44786 51.6426)\n\n\nwd:Q8065\nwd:Q113288859\nwd:Q843\n1666\nwd:Q843\nPakistan\n2022 Pakistan floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q20630431\nwd:Q1061\n70\nwd:Q668\nIndia\n2015 Gujarat flood\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q118433941\nwd:Q1263\n17\nwd:Q38\nItaly\n2023 Emilia-Romagna floods\nnatural disaster\nNA\n\n\n\n\n\n\n\nThis table has 1516 rows and documents 792 flood events."
  },
  {
    "objectID": "3_curate_wikidata.html#basic-query",
    "href": "3_curate_wikidata.html#basic-query",
    "title": "Curate wikidata",
    "section": "",
    "text": "We query the Wikidata Triplestore through the {glitter} R package (ref).\nHere are the initial results we get when performing this query:\n\n\n\n\n\nwhat\nflood\nloc\ndeathtoll\ncountry\ncountry_label\nflood_label\nwhat_label\ncoords\n\n\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q6886\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q7788\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q15175\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q19206\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q43934\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q45208\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q6401352\n85\nwd:Q148\nPeople's Republic of China\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q6886\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q7788\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q15175\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q19206\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q43934\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q45208\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q14628797\nwd:Q6401352\n85\nwd:Q159\nRussia\n2013 China–Russia floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q119109771\nwd:Q790\n51\nwd:Q790\nHaiti\n2023 Haiti floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q122311510\nwd:Q10388860\n47\nwd:Q155\nBrazil\n2023 Rio Grande do Sul floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q1599758\nwd:Q183\n16\nwd:Q183\nGermany\nflood disaster\nnatural disaster\nPoint(9.44786 51.6426)\n\n\nwd:Q8065\nwd:Q113288859\nwd:Q843\n1666\nwd:Q843\nPakistan\n2022 Pakistan floods\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q20630431\nwd:Q1061\n70\nwd:Q668\nIndia\n2015 Gujarat flood\nnatural disaster\nNA\n\n\nwd:Q8065\nwd:Q118433941\nwd:Q1263\n17\nwd:Q38\nItaly\n2023 Emilia-Romagna floods\nnatural disaster\nNA\n\n\n\n\n\n\n\nThis table has 1516 rows and documents 792 flood events."
  },
  {
    "objectID": "3_curate_wikidata.html#add-coordinates",
    "href": "3_curate_wikidata.html#add-coordinates",
    "title": "Curate wikidata",
    "section": "Add coordinates",
    "text": "Add coordinates\nNow we try and complete our dataset with coordinates, for the events that do not come directly with coordinates. We perform the task thanks to the linked nature of Wikidata’s knowledge graph.\n\nLocations\nHere is a function that collects data for each location identifier about:\n\ncountry of the location (country_loc)\ncoordinates of the location (coords_loc)\ntype of location (loc_type)\n\nWe apply this function to all locations appearing in wd_raw:\n\n\nCountries\nFor some events, location is not provided, only country. We still use this information, though imprecise, to locate these.\nHere is a function that collects data for each country identifier about the coordinates of the location (coords_country)\n\n\npng \n  2 \n\n\n\nWe apply this function to all countries appearing in the raw dataset which might provide us with coordinates for the events, when missing.\n\n\nIncorporate to data\nNow we update the data about floods taking into account that supplementary data about countries, and locations:\nThe coordinates for the flood events are thus inferred from:"
  },
  {
    "objectID": "3_curate_wikidata.html#get-and-clean-dates",
    "href": "3_curate_wikidata.html#get-and-clean-dates",
    "title": "Curate wikidata",
    "section": "Get and clean dates",
    "text": "Get and clean dates\nEach flood event in Wikidata might come with all or part of the information regarding time of occurrence (wdt:P585), start time (wdt:P580) and end time (wdt:P582).\nWe write a function which collects this information for each flood event.\n\n\npng \n  2 \n\n\nWe then apply this function to all locations mentioned in wd_raw:\nThere is a certain heterogeneity in the way information about dates is provided. The flood events’ time of occurrence might be provided through the properties\n\npoint in time (P585)\nstart time (P580)\nend time (P582)\n\nWe infer the date of a flood event in that order of priority\n\nprimarily as the date provided by “point in time” (direct)\nOR by the average date between “start time” and “end time” if they are both provided (start or end),\nOR by start time or end time if only one of them is provided (av_start_end)\nOR by a year provided in flood labels in the form of 4 digits-words if possible (flood_label)\n\nFinally, the dates provided in the dataset for the flood events correspond to the estimate given by:\n\n\n# A tibble: 5 × 2\n  date_from           n\n  &lt;chr&gt;           &lt;int&gt;\n1 1) direct         453\n2 2) av_start_end   145\n3 3) start_or_end    45\n4 4) flood_label    138\n5 &lt;NA&gt;               31\n\n\nand they correspond to a precision of:\n\n\n# A tibble: 4 × 2\n  date_precision     n\n  &lt;chr&gt;          &lt;int&gt;\n1 day              380\n2 month            147\n3 year             254\n4 &lt;NA&gt;              31"
  },
  {
    "objectID": "3_curate_wikidata.html#join-wd_raw-to-locations-and-dates",
    "href": "3_curate_wikidata.html#join-wd_raw-to-locations-and-dates",
    "title": "Curate wikidata",
    "section": "Join wd_raw to locations and dates",
    "text": "Join wd_raw to locations and dates"
  },
  {
    "objectID": "3_curate_wikidata.html#add-wiki-sites",
    "href": "3_curate_wikidata.html#add-wiki-sites",
    "title": "Curate wikidata",
    "section": "Add wiki sites",
    "text": "Add wiki sites\nWe collect all wikipedia pages (in all languages) relative to the events."
  },
  {
    "objectID": "3_curate_wikidata.html#add-images",
    "href": "3_curate_wikidata.html#add-images",
    "title": "Curate wikidata",
    "section": "Add images",
    "text": "Add images\nWe also collect images related to the flood events (wikidata property wdt:P18) when available"
  },
  {
    "objectID": "3_curate_wikidata.html#add-categories",
    "href": "3_curate_wikidata.html#add-categories",
    "title": "Curate wikidata",
    "section": "Add categories",
    "text": "Add categories"
  },
  {
    "objectID": "3_curate_wikidata.html#join-everything",
    "href": "3_curate_wikidata.html#join-everything",
    "title": "Curate wikidata",
    "section": "Join everything",
    "text": "Join everything"
  },
  {
    "objectID": "index.html#wikipedia-history-topics-and-controversies",
    "href": "index.html#wikipedia-history-topics-and-controversies",
    "title": "Online reports and narrations of flood events",
    "section": "Wikipedia history, topics and controversies",
    "text": "Wikipedia history, topics and controversies\n\n\n\n\n\nFigure 3: Time delay (in years) between events and revisions to the Wikipedia articles documenting them. The delay might be negative (the edits about an event began before the recorded, average date for the event, hinting to an event with long duration or event with a low-precision recorded date). The color indicates the precision of the recorded event date (it can be accurate to the day, month or year).\n\n\n\n\nFigure 3 shows that most of the writing of Wikipedia articles related to flood events take place during the month of their occurrence (except of course when Wikipedia did not exist (before 2001) or when it was still moderately used to document current events. This highlights the fact that Wikipedia articles about recent flood events can be viewed as news rather than encyclopedic reports on past events. Conversely, one can argue that articles exhibiting a large proportion of revisions implemented a long time after the occurrence of the event could be indicative of an ongoing debate or controversy, or be the ongoing focus of some social or human interest. Notez que je ne l’ai pas fait pour l’instant car je croule déjà sous les données, mais il serait possible (et pas trop compliqué) de récupérer les statistiques de consultation de chacune des pages (et donc de considérer l’intérêt porté à un article du point de vue du lecteur plutôt que du point de vue du créateur de contenu…). Est-ce que vous pensez que je dois me lancer là-dedans?\n\n\n\n\n\nFigure 4: Topics identified by the Reinert classification method. Based on the over-represented terms in each cluster we propose the following labelling of the classes: ‘governance’ for cluster1, ‘relief’ for cluster2, ‘damage’ for cluster3, ‘hydrology’ for cluster4, ‘anticipation’ for cluster5, and ‘weather’ for cluster6.\n\n\n\n\n\n\n\n\n\nFigure 5: Link between total article’s length and topics identified by the Reinert classification method. The articles are classified into 4 categories according to their lengths k (number of segments used for the Reinert classification and identification of topics). The 25% shortest articles represent 1&lt;k&lt;=4 segments while the 25% longest represent 26&lt;k&lt;860 segments. The proportion of segments falling into each category is calculated and the distribution of these proportions is displayed through boxplots for each article length category. The red dots correspond to the median proportions of topics throughout all articles irrespective of articles’ length.\n\n\n\n\nFigure 5 shows that the length of the article is probably a very important factor in the topics addressed (or conversely, the topics addressed determine the length of the article), with shorter articles corresponding to factual statements regarding physical features of the event (weather), and justifying reporting that event based on its consequences (damage), while longer articles might convey more extensive reports on the physical causes (hydrology) and management of the crisis (anticipation, governance, relief).\n\n\n\n\n\nFigure 6: a) Mean length of edits as a function of number of edits. A relative length of edit for each article is calculated based on this relationship. b) Relative length of edit as a function of total length. A measure of article curation (independent of total length) is calculated based on this relationship. The articles in language ‘simple’ (for ‘simple English’) being destined to be particularly synthetic, we did not take include them in the model.\n\n\n\n\nFigure 6 .a shows that beyond a few edits (here, we consider the threshold is 10), the mean edit length for an article depends on the total number of edits for that same article, in an approximately linear relationship with both variables being log-transformed. The more edits a page has undergone, the lower the mean edit length: there is a tendency towards lower mean edit length as the page ‘matures’, with edits in a more advanced writing stage corresponding to suppressions, corrections, or slight modifications while edits at the beginning of the writing process tend to be more frequently text additions. We consider the difference between actual mean edit length edit and predicted mean edit length (based on number of edits) as a measure of relative edit length (it corresponds to a measure of mean edit length decorrelated from this previously described writing stage effect). By construction and as shown by Figure 6 .b, the relative edit length is highly correlated to total article length, though we would like to dispose of a length-independent curation measure for further analyses purposes. Hence we calculate the curation score based on the residuals of the linear relationship of the relative edit length to total length (both log-transformed). These residuals are normalized to correspond to scores ranging from -1 (rather lowly curated articles) to 1 (very highly curated articles). We argue that this could be used as a measure of a particular effort having been devoted to the establishment of the current text and could thus be interpreted as a sign of possible controversy or debate in its writing process.\n\n\n\n\n\nFigure 7: a) Effect of the article being in a local language on curation. b) Effect of deathtoll and of the article being in a local language on curation.\n\n\n\n\nFigure 7 .a shows that the articles’ being written in a local language (considering the event location) tends to be associated with a lower level of article curation (effect estimate= -0.084, t value=-10, Pr(&gt;|t|)=0). This could be due to local articles being used more as information or managing crises tools than educational or encyclopedic carefully curated sources of knowledge. This hypothesis is reinforced by Figure 7 .b which shows that the higher the deathtoll of an event, the less curated the local articles (slope for local articles -0.02, t value= -4.32, Pr(&gt;|t|)=0.00002)."
  },
  {
    "objectID": "index.html#wikipedia-history-topics-and-curation",
    "href": "index.html#wikipedia-history-topics-and-curation",
    "title": "Online reports and narrations of flood events",
    "section": "Wikipedia history, topics and curation",
    "text": "Wikipedia history, topics and curation\n\n\n\n\n\nFigure 3: Time delay (in years) between events and revisions to the Wikipedia articles documenting them. The delay might be negative (the edits about an event began before the recorded, average date for the event, hinting to an event with long duration or event with a low-precision recorded date). The color indicates the precision of the recorded event date (it can be accurate to the day, month or year).\n\n\n\n\nFigure 3 shows that most of the writing of Wikipedia articles related to flood events take place during the month of their occurrence (except of course when Wikipedia did not exist (before 2001) or when it was still moderately used to document current events. This highlights the fact that Wikipedia articles about recent flood events can be viewed as news rather than encyclopedic reports on past events. Conversely, one can argue that articles exhibiting a large proportion of revisions implemented a long time after the occurrence of the event could be indicative of an ongoing debate or controversy, or be the ongoing focus of some social or human interest. Notez que je ne l’ai pas fait pour l’instant car je croule déjà sous les données, mais il serait possible (et pas trop compliqué) de récupérer les statistiques de consultation de chacune des pages (et donc de considérer l’intérêt porté à un article du point de vue du lecteur plutôt que du point de vue du créateur de contenu…). Est-ce que vous pensez que je dois me lancer là-dedans?\n\n\n\n\n\nFigure 4: Topics identified by the Reinert classification method. Based on the over-represented terms in each cluster we propose the following labelling of the classes: ‘governance’ for cluster1, ‘relief’ for cluster2, ‘damage’ for cluster3, ‘hydrology’ for cluster4, ‘anticipation’ for cluster5, and ‘weather’ for cluster6.\n\n\n\n\n\n\n\n\n\nFigure 5: Link between total article’s length and topics identified by the Reinert classification method. The articles are classified into 4 categories according to their lengths k (number of segments used for the Reinert classification and identification of topics). The 25% shortest articles represent 1&lt;k&lt;=4 segments while the 25% longest represent 26&lt;k&lt;860 segments. The proportion of segments falling into each category is calculated and the distribution of these proportions is displayed through boxplots for each article length category. The red dots correspond to the median proportions of topics throughout all articles irrespective of articles’ length.\n\n\n\n\nFigure 5 shows that the length of the article is probably a very important factor in the topics addressed (or conversely, the topics addressed determine the length of the article), with shorter articles corresponding to factual statements regarding physical features of the event (weather), and justifying reporting that event based on its consequences (damage), while longer articles might convey more extensive reports on the physical causes (hydrology) and management of the crisis (anticipation, governance, relief).\n\n\n\n\n\nFigure 6: a) Mean length of edits as a function of number of edits. A relative length of edit for each article is calculated based on this relationship. b) Relative length of edit as a function of total length. A measure of article curation (independent of total length) is calculated based on this relationship. The articles in language ‘simple’ (for ‘simple English’) being destined to be particularly synthetic, we did not take include them in the model.\n\n\n\n\nFigure 6 .a shows that beyond a few edits (here, we consider the threshold is 10), the mean edit length for an article depends on the total number of edits for that same article, in an approximately linear relationship with both variables being log-transformed. The more edits a page has undergone, the lower the mean edit length: there is a tendency towards lower mean edit length as the page ‘matures’, with edits in a more advanced writing stage corresponding to suppressions, corrections, or slight modifications while edits at the beginning of the writing process tend to be more frequently text additions. We consider the difference between actual mean edit length edit and predicted mean edit length (based on number of edits) as a measure of relative edit length (it corresponds to a measure of mean edit length decorrelated from this previously described writing stage effect). By construction and as shown by Figure 6 .b, the relative edit length is highly correlated to total article length, though we would like to dispose of a length-independent curation measure for further analyses purposes. Hence we calculate the curation score based on the residuals of the linear relationship of the relative edit length to total length (both log-transformed). These residuals are normalized to correspond to scores ranging from -1 (rather lowly curated articles) to 1 (very highly curated articles). We argue that this could be used as a measure of a particular effort having been devoted to the establishment of the current text and could thus be interpreted as a sign of possible controversy or debate in its writing process.\n\n\n\n\n\nFigure 7: Proportion of topics in each article according to its curation level. We classified articles into two categories representing the 33% most curated articles (high curation) vs all other articles. For each class we tested the difference in proportion based on a Wilcoxon rank test.\n\n\n\n\nFigure 7 shows that articles with high levels of curation tend to deal with topics such as relief (diff=0.0454944, p-value=0.00007), and governance (diff=0.0281336, p-value=0.00133), while weather ((diff=-0.0227273, p-value=0.02902)) is a bit less addressed. This hints at relief and governance being sensitive topics, which probably require and elicit more careful editing, discussion and fact-checking than e.g. reports on weather.\n\n\n\n\n\nFigure 8: a) Effect of the article being in a local language on curation. b) Effect of deathtoll and of the article being in a local language on curation.\n\n\n\n\nFigure 8 .a shows that the articles’ being written in a local language (considering the event location) tends to be associated with a lower level of article curation (effect estimate= -0.084, t value=-10, Pr(&gt;|t|)=0). This could be due to local articles being used more as information or managing crises tools than educational or encyclopedic carefully curated sources of knowledge. This hypothesis is reinforced by Figure 8 .b which shows that the higher the deathtoll of an event, the less curated the local articles (slope for local articles -0.02, t value= -4.32, Pr(&gt;|t|)=0.00002)."
  },
  {
    "objectID": "index.html#wikipedia-articles-description",
    "href": "index.html#wikipedia-articles-description",
    "title": "Online reports and narrations of flood events",
    "section": "Wikipedia articles’ description",
    "text": "Wikipedia articles’ description\nThere are 2630 Wikipedia pages associated to these events (i.e. on average 2.51 Wikipedia pages per event). 727 flood events are associated to at least one Wikipedia page.\n455 Wikipedia pages are in English. Out of the 2175 remaining pages, we could translate most pages to English, except 175 pages which were in languages that Google Translate did not support. We based all subsequent textometric analyses on the texts in English, either natively so or translated.\nThe average length of articles (in English or translated to English) is 4348 characters. The 10% shortest articles represent less than 448 characters and the 10% longest ones are more than 9362 characters long.\nThere are 216245 revisions that produced the Wikipedia pages as they appear to this date, which represents an average 82 revisions per page. 175107 (80.98%) of these revisions appear to have been done by human editors and not bots (Wikipedia usernames do not contain the strings “bot” or “Bot”). There are 44109 distinct editors, 40101 (90.91%) of which appear to be humans. On average, each human editor in our corpus is responsible for 4.37 edits. The number of articles (in the corpus) edited by each human editor is distributed as follows:\n\n\n\n\n\nnumber_of_articles_edited\nnumber_of_editors\nproportion_of_editors\n\n\n\n\n(0,1]\n27372\n68.26\n\n\n(1,2]\n8396\n20.94\n\n\n(2,5]\n2976\n7.42\n\n\n(5,10]\n862\n2.15\n\n\n(10,100]\n487\n1.21\n\n\n(100,400]\n8\n0.02"
  },
  {
    "objectID": "index.html#wikipedia-articles-history",
    "href": "index.html#wikipedia-articles-history",
    "title": "Online reports and narrations of flood events",
    "section": "Wikipedia articles’ history",
    "text": "Wikipedia articles’ history\n\n\n\n\n\nFigure 4: Time delay (in years) between events and a) revisions to the Wikipedia articles documenting them b) views of the Wikipedia articles. The delay might be negative (the edits or views about an event began before the recorded, average date for the event, hinting to an event with long duration or event with a low-precision recorded date). The color indicates the precision of the recorded event date (it can be accurate to the day, month or year).\n\n\n\n\nFigure 4 .a shows that most of the writing of Wikipedia articles related to flood events take place during the month of their occurrence (except of course when Wikipedia did not exist (before 2001) or when it was still moderately used to document current events. This highlights the fact that Wikipedia articles about recent flood events are written as news rather than encyclopedic reports on past events. Figure 4 .b shows that views (consultations) of the pages, on the other hand, are distributed more evenly through time. We cannot access the data relative to views before July 2015 so that early views of articles dated before 2015 cannot be known. For articles dated after 2015, although most views occur about events which occurred between 2010 and 2020 occur 5 to 10 years after the fact."
  },
  {
    "objectID": "index.html#wikipedia-articles-topics",
    "href": "index.html#wikipedia-articles-topics",
    "title": "Online reports and narrations of flood events",
    "section": "Wikipedia articles’ topics",
    "text": "Wikipedia articles’ topics\n\n\n\n\n\nFigure 5: Topics identified by the Reinert classification method. Based on the over-represented terms in each cluster we propose the following labelling of the classes: ‘governance’ for cluster1, ‘relief’ for cluster2, ‘damage’ for cluster3, ‘hydrology’ for cluster4, ‘anticipation’ for cluster5, and ‘weather’ for cluster6.\n\n\n\n\n\n\n\n\n\nFigure 6: Link between total article’s length and topics identified by the Reinert classification method. The articles are classified into 4 categories according to their lengths k (number of segments used for the Reinert classification and identification of topics). The 25% shortest articles represent 1&lt;k&lt;=4 segments while the 25% longest represent 26&lt;k&lt;860 segments. The proportion of segments falling into each category is calculated and the distribution of these proportions is displayed through boxplots for each article length category. The red dots correspond to the median proportions of topics throughout all articles irrespective of articles’ length.\n\n\n\n\nFigure 6 shows that the length of the article is probably a very important factor in the topics addressed (or conversely, the topics addressed determine the length of the article), with shorter articles corresponding to factual statements regarding physical features of the event (weather), and justifying reporting that event based on its consequences (damage), while longer articles might convey more extensive reports on the physical causes (hydrology) and management of the crisis (anticipation, governance, relief).\n\n\n\n\n\nFigure 7: a) Mean length of edits as a function of number of edits. A relative length of edit for each article is calculated based on this relationship. b) Relative length of edit as a function of total length. A measure of article curation (independent of total length) is calculated based on this relationship. The articles in language ‘simple’ (for ‘simple English’) being destined to be particularly synthetic, we did not take include them in the model.\n\n\n\n\nFigure 7 .a shows that beyond a few edits (here, we consider the threshold is 10), the mean edit length for an article depends on the total number of edits for that same article, in an approximately linear relationship with both variables being log-transformed. The more edits a page has undergone, the lower the mean edit length: there is a tendency towards lower mean edit length as the page ‘matures’, with edits in a more advanced writing stage corresponding to suppressions, corrections, or slight modifications while edits at the beginning of the writing process tend to be more frequently text additions. We consider the difference between actual mean edit length edit and predicted mean edit length (based on number of edits) as a measure of relative edit length (it corresponds to a measure of mean edit length decorrelated from this previously described writing stage effect). By construction and as shown by Figure 7 .b, the relative edit length is highly correlated to total article length, though we would like to dispose of a length-independent curation measure for further analyses purposes. Hence we calculate the curation score based on the residuals of the linear relationship of the relative edit length to total length (both log-transformed). These residuals are normalized to correspond to scores ranging from -1 (rather lowly curated articles) to 1 (very highly curated articles). We argue that this could be used as a measure of a particular effort having been devoted to the establishment of the current text and could thus be interpreted as a sign of possible controversy or debate in its writing process.\n\n\n\n\n\nFigure 8: Proportion of topics in each article according to its curation level. We classified articles into two categories representing the 33% most curated articles (high curation) vs all other articles. For each class we tested the difference in proportion based on a Wilcoxon rank test.\n\n\n\n\nFigure 8 shows that articles with high levels of curation tend to deal with topics such as relief (diff=0.045, p-value=0.00007), and governance (diff=0.028, p-value=0.00133), while weather ((diff=-0.023, p-value=0.02902)) is a bit less addressed. This hints at relief and governance being sensitive topics, which probably require and elicit more careful editing, discussion and fact-checking than e.g. reports on weather.\n\n\n\n\n\nFigure 9: a) Effect of the article being in a local language on curation. b) Effect of deathtoll and of the article being in a local language on curation.\n\n\n\n\nFigure 9 .a shows that the articles’ being written in a local language (considering the event location) tends to be associated with a lower level of article curation (effect estimate= -0.084, t value=-10, Pr(&gt;|t|)=0). This could be due to local articles being used more as information or managing crises tools than educational or encyclopedic carefully curated sources of knowledge. This hypothesis is reinforced by Figure 9 .b which shows that the higher the deathtoll of an event, the less curated the local articles (slope for local articles -0.02, t value= -4.32, Pr(&gt;|t|)=0.00002)."
  }
]