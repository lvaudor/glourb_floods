[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "General purpose",
    "section": "",
    "text": "Code\nlibrary(glitter)\nlibrary(tidyverse)\nlibrary(ggpubr)\n\n\n\n\nThis study’s objectives are to\n\ncollect and assess the information provided by the Wikimedia initiative (Wikidata, Wikipedia, Wikimedia Commons) on flood events.\ncompare this data, which is crowdsourced, to an institutionnally curated database on the same topic.\nuse this data to characterize the historical importance and human impact of the flood events documented.\n\n\n\n\nOpen Access Journal. The journal’s scope includes but is not limited to:\n\nDigital Tools and Methods in Humanities Research: DHQ publishes articles that showcase innovative digital tools, methods, and approaches used in humanities scholarship. This can involve text analysis, data visualization, digital archives, GIS (Geographic Information Systems), network analysis, and more.\nCritical Assessment of Digital Technologies in Humanities Studies: DHQ features critical evaluations and discussions about the implications, challenges, and limitations of using digital technologies in humanities research. This includes considerations of ethics, accessibility, and cultural implications of digital humanities work.\nInterdisciplinary Collaborations: The journal promotes interdisciplinary collaborations by highlighting research at the intersection of humanities disciplines and technology. It covers collaborations between historians, literary scholars, linguists, cultural studies scholars, and experts in computer science, data science, and information technology.\nDigital Pedagogy and Teaching Approaches: DHQ discusses innovative pedagogical approaches that integrate digital tools and methods into humanities teaching. This includes case studies, reviews, and discussions on the use of technology in the classroom to enhance learning experiences.\nDigital Humanities Projects and Case Studies: The journal publishes case studies and reports on digital humanities projects, initiatives, and experiments, providing insights into the practical application of digital methods in various humanities fields.\nOpen Access and Open Data: DHQ supports open access and open data principles, often discussing issues related to data curation, preservation, and accessibility in the context of digital humanities research."
  },
  {
    "objectID": "index.html#aim-of-the-article",
    "href": "index.html#aim-of-the-article",
    "title": "General purpose",
    "section": "",
    "text": "This study’s objectives are to\n\ncollect and assess the information provided by the Wikimedia initiative (Wikidata, Wikipedia, Wikimedia Commons) on flood events.\ncompare this data, which is crowdsourced, to an institutionnally curated database on the same topic.\nuse this data to characterize the historical importance and human impact of the flood events documented."
  },
  {
    "objectID": "index.html#journaux-potentiels",
    "href": "index.html#journaux-potentiels",
    "title": "glourb_floods",
    "section": "",
    "text": "Open Access Journal. The journal’s scope includes but is not limited to:\n\nDigital Tools and Methods in Humanities Research: DHQ publishes articles that showcase innovative digital tools, methods, and approaches used in humanities scholarship. This can involve text analysis, data visualization, digital archives, GIS (Geographic Information Systems), network analysis, and more.\nCritical Assessment of Digital Technologies in Humanities Studies: DHQ features critical evaluations and discussions about the implications, challenges, and limitations of using digital technologies in humanities research. This includes considerations of ethics, accessibility, and cultural implications of digital humanities work.\nInterdisciplinary Collaborations: The journal promotes interdisciplinary collaborations by highlighting research at the intersection of humanities disciplines and technology. It covers collaborations between historians, literary scholars, linguists, cultural studies scholars, and experts in computer science, data science, and information technology.\nDigital Pedagogy and Teaching Approaches: DHQ discusses innovative pedagogical approaches that integrate digital tools and methods into humanities teaching. This includes case studies, reviews, and discussions on the use of technology in the classroom to enhance learning experiences.\nDigital Humanities Projects and Case Studies: The journal publishes case studies and reports on digital humanities projects, initiatives, and experiments, providing insights into the practical application of digital methods in various humanities fields.\nOpen Access and Open Data: DHQ supports open access and open data principles, often discussing issues related to data curation, preservation, and accessibility in the context of digital humanities research."
  },
  {
    "objectID": "index.html#get-coordinates-if-possible",
    "href": "index.html#get-coordinates-if-possible",
    "title": "glourb_floods",
    "section": "Get coordinates if possible",
    "text": "Get coordinates if possible\n\nGet coordinates and country of locations\nNow we try and complete geographical informations based on Wikidata. For each location identifier, we collect data about\n\ncountry of the location (country_loc)\ncoordinates of the location (coords_loc)\ntype of location (loc_type)\n\n\n\nCode\nget_loc_info=function(loc_id){\n  result=spq_init() %&gt;%\n    spq_set(loc=loc_id) %&gt;% \n    spq_add(\"?loc wdt:P17 ?country_loc\") %&gt;% \n    spq_add(\"?loc wdt:P625 ?coords_loc\") %&gt;% \n    spq_add(\"?loc wdt:P31 ?loc_type\") %&gt;% \n    spq_label(loc, country_loc, loc_type) %&gt;% \n    spq_select(-loc) %&gt;% \n    spq_perform()\n  result\n}\n\n\nWe apply this query to all locations mentioned in wd_raw:\n\n\nCode\nif(!file.exists(\"data/locs.RDS\")){\n  locs=wd_raw %&gt;%\n    select(loc) %&gt;% \n    unique() %&gt;% \n    na.omit() %&gt;% \n    mutate(data=purrr::map(loc,get_loc_info)) %&gt;% \n    tidyr::unnest(data)\n  saveRDS(locs, \"data/locs.RDS\")\n}\nlocs=readRDS(\"data/locs.RDS\")\n\n\nNow we update the data about floods taking into account that supplementary data about locations:\n\n\nCode\nwd_loc=wd_raw %&gt;% \n  left_join(locs,by=\"loc\") %&gt;%\n  mutate(country_label=case_when(country_label==\"\"~country_loc_label,\n                                 country_label!=\"\"~country_label)) %&gt;% \n  mutate(country=case_when(is.na(country)~country_loc,\n                           !is.na(country)~country)) %&gt;% \n  mutate(coords_from=case_when(!is.na(coords)~\"flood\",\n                               is.na(coords)~\"location\")) %&gt;% \n  mutate(country=stringr::str_replace_all(country, \"http://www.wikidata.org/entity/\", \"wd:\"))\n\n\nWarning in left_join(., locs, by = \"loc\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 2 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n\nGet coordinates of countries\nWe also want to get country coordinates\n\n\nCode\nget_country_info=function(country_id){\n  result=spq_init() %&gt;%\n    spq_set(country=country_id) %&gt;% \n    spq_add(\"?country wdt:P625 ?coords_country\") %&gt;%\n    spq_select(-country) %&gt;% \n    spq_perform() \n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/countries.RDS\")){\n  countries=wd_loc %&gt;%\n    select(country) %&gt;% \n    unique() %&gt;% \n    na.omit() %&gt;% \n    mutate(data=purrr::map(country,get_country_info)) %&gt;% \n    tidyr::unnest(data)\n  saveRDS(countries, \"data/countries.RDS\")\n}\ncountries=readRDS(\"data/countries.RDS\")\n\n\nNow we update the data about floods taking into account that supplementary data about countries:\n\n\nCode\nwd_loc=wd_loc %&gt;% \n  left_join(countries,by=\"country\") %&gt;%\n  mutate(coords_from=case_when(is.na(coords) & is.na(coords_loc) & !is.na(coords_country) ~\"3) country\",\n                               !is.na(coords_loc)~\"2) location\",\n                               !is.na(coords)~\"1) not infered: direct\",\n                               TRUE~\"4) no coordinates\")) %&gt;% \n  mutate(coords=case_when(is.na(coords)~coords_loc,\n                          !is.na(coords)~coords)) %&gt;%\n  mutate(coords=case_when(is.na(coords)~coords_country,\n                          !is.na(coords)~coords)) %&gt;% \n  select(-country,-country_loc_label,-coords_country,-coords_loc\n         ,-loc_type_label,-contains(\"loc\")) %&gt;% \n  unique()\n\n\nThe coordinates for the flood events are thus inferred from:\n\n\nCode\nwd_loc %&gt;% \n  group_by(coords_from) %&gt;% \n  summarise(n=n())\n\n\n# A tibble: 4 × 2\n  coords_from                n\n  &lt;chr&gt;                  &lt;int&gt;\n1 1) not infered: direct   122\n2 2) location              696\n3 3) country               557\n4 4) no coordinates         94"
  },
  {
    "objectID": "index.html#clean-dates",
    "href": "index.html#clean-dates",
    "title": "glourb_floods",
    "section": "Clean dates",
    "text": "Clean dates\n\nwd_loc2=wd_loc %&gt;% \n  mutate(mstart=lubridate::round_date(start,\"month\"),\n         mend=lubridate::round_date(end,\"month\"),\n         mdate=lubridate::round_date(date,\"month\")) %&gt;% \n  mutate(mstart=case_when(is.na(mstart)~mdate,\n                          !is.na(mstart)~mstart)) %&gt;% \n  mutate(mend=case_when(is.na(mend)~mdate,\n                        !is.na(mend)~mend)) %&gt;% \n  group_by(mstart,mend,mdate) %&gt;% \n  tidyr::nest()# %&gt;% \n  #mutate()"
  },
  {
    "objectID": "index.html#select-variables-for-comparison",
    "href": "index.html#select-variables-for-comparison",
    "title": "glourb_floods",
    "section": "Select variables for comparison",
    "text": "Select variables for comparison\n\n# wd_comp=wd_loc %&gt;% \n#   select(flood,flood_label,country_label,deathtoll,start,end,date,coords)\n\nIn case coords are not provided, we approximate them with location coordinates (if available)."
  },
  {
    "objectID": "index.html#monthly-summary",
    "href": "index.html#monthly-summary",
    "title": "glourb_floods",
    "section": "monthly summary",
    "text": "monthly summary\n\ngfd= gfd_raw %&gt;%\n  mutate(month_began=floor_date(lubridate::mdy(dfo_began),\"month\"),\n         month_ended=ceiling_date(lubridate::mdy(dfo_ended),\"month\")) %&gt;%\n  tidyr::pivot_longer(cols=starts_with(\"month_\"),names_to=\"start_end\",values_to=\"month\")\n# \n# tt=tib_gdf %&gt;%\n#   select(index,month) %&gt;%\n#   group_by(index) %&gt;%\n#   tidyr::nest(data=month) %&gt;%\n#   mutate(month=purrr::map(.x=data, ~seq(first(.x$month),last(.x$month),\"month\"))) %&gt;%\n#   tidyr::unnest(month) %&gt;%\n#   ungroup() %&gt;%\n#   group_by(month) %&gt;%\n#   summarise(n=n())\n# ggplot(tt, aes(x=month,y=n))+geom_path()"
  },
  {
    "objectID": "index.html#monthly-summary-1",
    "href": "index.html#monthly-summary-1",
    "title": "glourb_floods",
    "section": "monthly summary",
    "text": "monthly summary\n\n# all_dates=tibble::tibble(date=seq(from=lubridate::ymd(\"2000-01-01\"),\n#                                   to=lubridate::ymd(\"2019-01-01\"),\n#                                   by=\"month\"))\n# wd=wd_raw%&gt;%\n#   mutate(date=lubridate::round_date(date,'month'))%&gt;%\n#   filter(date&gt;lubridate::ymd(\"2000-01-01\"),\n#          date&lt;lubridate::ymd(\"2019-01-01\")) %&gt;%\n#   group_by(date) %&gt;%\n#   summarise(n=n()) %&gt;%\n#   full_join(all_dates) %&gt;%\n#   mutate(n=replace_na(n,0)) %&gt;%\n#   arrange(date)\n\n# ggplot(tibs, aes(x=date,y=n))+geom_path()\n# dim(tib)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site gathers elements regarding flood events documented both through participatory data (Wikidata, Wikipedia) and physical (remote sensing) assessment. It questions the link between these data and what we can infer from them, in particular regarding the impact of floods on humans."
  },
  {
    "objectID": "index.html#get-and-clean-dates",
    "href": "index.html#get-and-clean-dates",
    "title": "glourb_floods",
    "section": "Get and clean dates",
    "text": "Get and clean dates\n\n\nCode\nget_date_info=function(flood_id,type=\"P585\"){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(glue::glue(\"?flood p:{type}/psv:{type} ?datestatement\")) %&gt;% \n    spq_add(\"?datestatement wikibase:timeValue ?datetime\") %&gt;%\n    spq_add(\"?datestatement wikibase:timePrecision ?precision\",.required=FALSE) %&gt;%\n    spq_mutate(date=as.date(datetime)) %&gt;% \n    spq_select(-datestatement,-datetime) %&gt;% \n    spq_perform()\n  result\n}\n\n\nWe apply this query to all locations mentioned in wd_raw:\n\n\nCode\nfill_void=function(tib,name=\"date\"){\n  if(nrow(tib)==0){\n    tib=tibble::tibble(flood=NA,\n                       date=NA,\n                       precision=NA)\n  }\n  tib=tib %&gt;% select(date, precision)\n  colnames(tib)=c(name,paste0(name,\"_precision\"))\n  return(tib)\n}\nif(!file.exists(\"data/dates.RDS\")){\n  dates=wd_raw %&gt;%\n    select(flood,flood_label)%&gt;% \n    unique() %&gt;% \n    mutate(flood=stringr::str_replace_all(flood,\n                                          \"http://www.wikidata.org/entity/\", \"wd:\")) %&gt;%\n    mutate(date=purrr::map(flood,get_date_info)) %&gt;% \n    mutate(start=purrr::map(flood,get_date_info, type=\"P580\")) %&gt;%\n    mutate(end=purrr::map(flood,get_date_info, type=\"P582\")) %&gt;%\n    mutate(date=purrr::map(date,fill_void)) %&gt;% \n    mutate(start=purrr::map(start,fill_void,name=\"start\")) %&gt;% \n    mutate(end=purrr::map(end,fill_void,name=\"end\")) %&gt;% \n    tidyr::unnest(c(date,start,end))\n  saveRDS(dates, \"data/dates.RDS\")\n}\n\n\n\n\nCode\ndates=readRDS(\"data/dates.RDS\") %&gt;% \n  mutate(date_from=case_when(!is.na(date)~\"direct\",\n                        (is.na(date) & !is.na(start))~\"start\",\n                        (is.na(date) & !is.na(end))~\"end\")) %&gt;% \n  mutate(date=case_when(!is.na(date)~date,\n                        (is.na(date) & !is.na(start))~start,\n                        (is.na(date) & !is.na(end))~end)) %&gt;% \n  mutate(date_label=case_when(is.na(date)~stringr::str_extract(flood_label,\"\\\\d{4}\"))) %&gt;% \n  mutate(date_from=case_when(!is.na(date_label)~\"flood_label\",\n                             is.na(date_label)~date_from)) %&gt;% \n  mutate(date=case_when(is.na(date) & !is.na(date_label)~paste0(date_label,\"-01-01\"),\n                        TRUE~date)) %&gt;% \n  filter(date_precision&gt;9|is.na(date_precision)) %&gt;% \n  mutate(date=lubridate::ymd(date),\n         start=lubridate::ymd(start),\n         end=lubridate::ymd(end))\n\n\n\n\nCode\ndates %&gt;% \n  group_by(date_from) %&gt;% \n  tally()\n\n\n# A tibble: 4 × 2\n  date_from       n\n  &lt;chr&gt;       &lt;int&gt;\n1 direct        346\n2 flood_label   119\n3 start         190\n4 &lt;NA&gt;           48\n\n\nJoin to dates and remove geological scale events\n\n\nCode\nwd=wd_raw  %&gt;% \n  select(-coords,-country,-country_label) %&gt;% \n  left_join(floodlocs,by=c(\"flood\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(dates, by=c(\"flood\"),\n            relationship =\"many-to-many\") %&gt;% \n  mutate(year=lubridate::year(date)) #%&gt;%\n  # filter(!is.na(coords)) %&gt;% \n  # group_by(flood) %&gt;%\n  # sf::st_as_sf(wkt=\"coords\") %&gt;% \n  # summarise(flood_label=first(flood_label),\n  #           coords_from=first(coords_from),\n  #           year=first(year),\n  #           date=first(date),\n  #           date_precision=first(date_precision),\n  #           start=first(start),\n  #           end=first(end),\n  #           country_label=paste0(unique(country_label),collapse=\";\"),\n  #           deathtoll=mean(deathtoll)) %&gt;% \n  # sf::st_centroid()"
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "glourb_floods",
    "section": "",
    "text": "# spq_add(\"?article schema:about ?flood\",.required=FALSE) %&gt;%  \n    # spq_add(\"?article schema:isPartOf &lt;https://en.wikipedia.org/&gt;\",.required=FALSE)"
  },
  {
    "objectID": "index.html#join-and-create-map",
    "href": "index.html#join-and-create-map",
    "title": "glourb_floods",
    "section": "Join and create map",
    "text": "Join and create map\n\nwd_locdate=wd_loc %&gt;% \n  mutate(flood=stringr::str_replace_all(flood,\n                                        \"http://www.wikidata.org/entity/\", \"wd:\")) %&gt;% \n  left_join(dates,by=\"flood\") %&gt;%\n  filter(date_precision&gt;9)\n\nWarning in left_join(., dates, by = \"flood\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 25 of `x` matches multiple rows in `y`.\nℹ Row 3 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nlibrary(leaflet) \nwd_map=wd_locdate %&gt;% \n  filter(!is.na(coords)) %&gt;% \n  sf::st_as_sf(wkt=\"coords\") %&gt;% \n  mutate(year=lubridate::year(date)) %&gt;% \n  mutate(popup=glue::glue(\"&lt;h1&gt;{flood_label}&lt;/h1&gt;\n                          &lt;p&gt;date:{date}&lt;/p&gt;\n                          &lt;p&gt;deathtoll:{deathtoll}&lt;/p&gt;\"))\n# Définition d'une échelle colorée \n# (en fonction de date de sortie) \npal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"),\n                    c(1648,1800,1900,1950,1980,2000,2010,2023)) \n# Création de la carte \nmap=leaflet(wd_map) %&gt;% # déf carte \n  addTiles() %&gt;% # ajout fond de carte\n  addCircleMarkers(col=~pal(year),\n                   popup = ~popup,\n                   clusterOptions = markerClusterOptions()) \n\nWarning in pal(year): Some values were outside the color scale and will be\ntreated as NA\n\nWarning in pal(year): Some values were outside the color scale and will be\ntreated as NA\n\n\n\nmap"
  },
  {
    "objectID": "index.html#prepare-for-comparison",
    "href": "index.html#prepare-for-comparison",
    "title": "General purpose",
    "section": "Prepare for comparison",
    "text": "Prepare for comparison\n\n\nCode\n# seqdates=function(start,end){\n#   if(is.na(start)|is.na(end)){return(lubridate::as_datetime(NA))}\n#   seq=seq(start,end,by=\"month\")\n#   return(seq)\n# }"
  },
  {
    "objectID": "index.html#add-wiki-sites",
    "href": "index.html#add-wiki-sites",
    "title": "glourb_floods",
    "section": "Add wiki sites",
    "text": "Add wiki sites\n\n\nCode\nget_wikisites=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?article schema:about ?flood\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform() %&gt;% \n    filter(stringr::str_detect(article,\"wikipedia\"))\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/wikisites.RDS\")){\n  wikisites=wd %&gt;%\n    #sf::st_drop_geometry() %&gt;% \n    select(flood,flood_label) %&gt;% \n    unique() %&gt;% \n    mutate(flood=stringr::str_replace_all(flood,\n                                          \"http://www.wikidata.org/entity/\", \"wd:\")) %&gt;%\n    mutate(wikisites=purrr::map(flood,get_wikisites)) %&gt;% \n    tidyr::unnest(c(wikisites))\n  saveRDS(wikisites, \"data/wikisites.RDS\")\n}\nwikisites=readRDS(\"data/wikisites.RDS\")"
  },
  {
    "objectID": "index.html#join-to-dates-and-remove-geological-scale-events",
    "href": "index.html#join-to-dates-and-remove-geological-scale-events",
    "title": "glourb_floods",
    "section": "Join to dates and remove geological scale events",
    "text": "Join to dates and remove geological scale events\n\n\nCode\nwd_locdate=wd_loc %&gt;% \n  mutate(flood=stringr::str_replace_all(flood,\n                                        \"http://www.wikidata.org/entity/\", \"wd:\")) %&gt;% \n  left_join(dates,by=c(\"flood\",\"flood_label\")) %&gt;%\n  filter(date_precision&gt;9|is.na(date_precision)) %&gt;% \n  mutate(year=lubridate::year(date)) %&gt;%\n  filter(!is.na(coords)) %&gt;% \n  group_by(flood) %&gt;% \n  sf::st_as_sf(wkt=\"coords\") %&gt;% \n  summarise(flood_label=first(flood_label),\n            coords_from=first(coords_from),\n            year=first(year),\n            date=first(date),\n            date_precision=first(date_precision),\n            start=first(start),\n            end=first(end),\n            country_label=paste0(unique(country_label),collapse=\";\"),\n            deathtoll=mean(deathtoll)) %&gt;% \n  sf::st_centroid() \n\n\nWarning in left_join(., dates, by = c(\"flood\", \"flood_label\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 25 of `x` matches multiple rows in `y`.\nℹ Row 3 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning."
  },
  {
    "objectID": "index.html#summary-data",
    "href": "index.html#summary-data",
    "title": "General purpose",
    "section": "",
    "text": "Code\nwd_events=readRDS(\"data/wd_events.RDS\")\nwd_full=readRDS(\"data/wd_full.RDS\")\nNwd=wd_events %&gt;% nrow()\nNaft1900=wd_events %&gt;% filter(year&gt;=1900) %&gt;% nrow()\nNaft2000=wd_events %&gt;% filter(year&gt;=2000) %&gt;% nrow()\nPropaft1900=Naft1900/Nwd\nPropaft2000=Naft2000/Nwd\n\n\nOur Wikidata base documents 811 flood events, 0.6300863% of which occurred after 1900 and 0.4401973% of which occurred after 2000.\n\n\nCode\nggplot(wd_events, aes(x=year))+\n  geom_histogram(breaks=c(0,1000,1100,1200,1300,1400,1500,1600,1700,1800,1850,1900,1950,2000,2023))\n\n\nWarning: Removed 157 rows containing non-finite values (`stat_bin()`).\n\n\nCode\nggplot(wd_events %&gt;% filter(year&gt;=2000), aes(x=year))+\n  geom_histogram(breaks=2000:2023)\n\n\n\n\n\nFigure 1: Distribution of flood events through time\n\n\n\n\n\n\n\nFigure 2: Distribution of flood events through time"
  },
  {
    "objectID": "index.html#try-and-find-correspondences",
    "href": "index.html#try-and-find-correspondences",
    "title": "General purpose",
    "section": "Try and find correspondences",
    "text": "Try and find correspondences\n\n\nCode\ntib=sf::st_as_sf(tib,wkt=\"coords\")\nflood_id=\"wd:Q106611659\"\n\n\nfind_corresponding_flood=function(flood_id){\n  tib_sub=tib %&gt;% filter(flood==flood_id)\n  tib_dist=tib %&gt;% \n    mutate(disttime=abs(tib$date-tib_sub$date),\n           distspace=sf::st_distance(tib,tib_sub)[,1]) %&gt;% \n    filter(flood!=flood_id) %&gt;% \n    filter(disttime&lt;60 & distspace&lt;10) %&gt;% \n    filter(disttime==min(disttime)|distspace==min(distspace)) %&gt;% \n    select(floodcorr=flood,\n           disttime,\n           distspace,\n           sourcecorr=source,\n           country_corr=country_label,\n           deathtoll_corr=deathtoll) %&gt;% \n    sf::st_drop_geometry()\n  if(nrow(tib_dist)==0){\n    tib_dist=tibble::tibble(floodcorr=NA,\n                            disttime=NA,\n                            distspace=NA,\n                            sourcecorr=NA,\n                            countrycorr=NA,\n                            deathtollcorr=NA)\n  }\n  return(tib_dist)\n}\nif(!file.exists(\"data/tibcorr.RDS\")){\ntibcorr=tib %&gt;% \n  mutate(data=purrr::map(flood,find_corresponding_flood)) %&gt;% \n  tidyr::unnest(data) %&gt;% \n  filter(source==\"wd\" & sourcecorr==\"gfd\")\nsaveRDS(tibcorr,\n        \"data/tibcorr.RDS\")\n}\ntibcorr=readRDS(\"data/tibcorr.RDS\")\ntruc=bind_rows(tibble::tibble(id=1:nrow(tibcorr),flood=tibcorr$flood),\n               tibble::tibble(id=1:nrow(tibcorr),flood=tibcorr$floodcorr))\ntruc=left_join(tib,truc, by=\"flood\",\n               relationship =\"many-to-many\") %&gt;% \n  select(id,flood) %&gt;%\n  filter(!is.na(id)) %&gt;% \n  group_by(id) %&gt;% \n  summarise(m =mean(id),do_union=FALSE) %&gt;% \n  sf::st_cast(\"LINESTRING\")"
  },
  {
    "objectID": "index.html#map-comparison",
    "href": "index.html#map-comparison",
    "title": "General purpose",
    "section": "Map comparison",
    "text": "Map comparison\n\n\nCode\nlibrary(leaflet) \ntib_comp_map=tib %&gt;%\n  sf::st_as_sf(wkt=\"coords\")\n# Définition d'une échelle colorée \n# (en fonction de date de sortie) \n# Création de la carte \npal=colorFactor(c(\"red\",\"blue\"), domain=c(\"wd\",\"dfo\"))\ncomp_map=leaflet(tib_comp_map)  %&gt;%\n  addProviderTiles(providers$Esri.NatGeoWorldMap) %&gt;% # ajout fond de carte\n  addCircleMarkers(col=~pal(source),\n                   popup =~popup,\n                   radius =~log(deathtoll+2)\n                   )  %&gt;%\n  addPolylines(data=joined_events,color=\"green\")\n\n\n\n\nCode\ncomp_map"
  },
  {
    "objectID": "index.html#basic-query",
    "href": "index.html#basic-query",
    "title": "glourb_floods",
    "section": "Basic query",
    "text": "Basic query\nWe query the Wikidata Triplestore through the {glitter} R package (ref).\n\n\nCode\nlibrary(glitter)\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nif(!file.exists(\"data/wd_raw.RDS\")){\n  wd_raw=spq_init() %&gt;%\n    spq_add(\"?flood wdt:P31/wdt:P279* wd:Q8068\") %&gt;% \n    spq_add(\"?flood wdt:P31 ?what\") %&gt;%\n    spq_add(\"?flood wdt:P625 ?coords\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P17 ?country\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P1120 ?deathtoll\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P276 ?loc\",.required=FALSE) %&gt;%\n    spq_label(flood,country,what) %&gt;%\n    spq_perform() %&gt;% \n    mutate(deathtoll=as.numeric(deathtoll)) %&gt;% \n    mutate(loc=stringr::str_replace_all(loc, \"http://www.wikidata.org/entity/\", \"wd:\"))\n  saveRDS(wd_raw,\"data/wd_raw.RDS\")\n}\nwd_raw=readRDS(\"data/wd_raw.RDS\") %&gt;% \n  mutate(country=stringr::str_replace_all(country, \"http://www.wikidata.org/entity/\", \"wd:\")) %&gt;% \n  mutate(flood=stringr::str_replace_all(flood, \"http://www.wikidata.org/entity/\", \"wd:\"))\nhead(wd_raw)\n\n\n# A tibble: 6 × 9\n  what        flood deathtoll country country_label flood_label what_label loc  \n  &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;\n1 http://www… wd:Q…      1666 wd:Q843 Pakistan      2022 Pakis… natural d… &lt;NA&gt; \n2 http://www… wd:Q…       116 wd:Q668 India         2022 India… natural d… &lt;NA&gt; \n3 http://www… wd:Q…       116 wd:Q902 Bangladesh    2022 India… natural d… &lt;NA&gt; \n4 http://www… wd:Q…       506 wd:Q258 South Africa  1987 South… natural d… wd:Q…\n5 http://www… wd:Q…       435 wd:Q258 South Africa  2022 KwaZu… natural d… wd:Q…\n6 http://www… wd:Q…        14 wd:Q258 South Africa  2022 East … natural d… wd:Q…\n# ℹ 1 more variable: coords &lt;chr&gt;\n\n\nThis table has 1587 rows and documents 804 flood events.\nThe degree of precision in the geographical location for each of these floods might vary. For each recorded flood event we might have access to all or part of these informations:\n\na location (loc) which might refer to a scale as varied as continent/sub-continent, country, basin, city, etc.\na country (country)\nspatial coordinates (coords)\n\nIn case location is not provided, we approximate it with country (if available).\n\n\nCode\nwd_raw=wd_raw %&gt;% \n  mutate(loc=case_when(is.na(loc)~country,\n                       !is.na(loc)~loc))"
  },
  {
    "objectID": "index.html#add-coordinates",
    "href": "index.html#add-coordinates",
    "title": "glourb_floods",
    "section": "Add coordinates",
    "text": "Add coordinates\nNow we try and complete geographical informations based on Wikidata. For each location identifier, we collect data about\n\ncountry of the location (country_loc)\ncoordinates of the location (coords_loc)\ntype of location (loc_type)\n\n\n\nCode\nget_loc_info=function(loc_id){\n  result=spq_init() %&gt;%\n    spq_set(loc=loc_id) %&gt;% \n    spq_add(\"?loc wdt:P17 ?country_loc\") %&gt;% \n    spq_add(\"?loc wdt:P625 ?coords_loc\") %&gt;% \n    spq_add(\"?loc wdt:P31 ?loc_type\") %&gt;% \n    spq_label(loc, country_loc, loc_type) %&gt;% \n    spq_select(-loc) %&gt;% \n    spq_perform()\n  result\n}\n\n\nWe apply this query to all locations mentioned in wd_raw:\n\n\nCode\nif(!file.exists(\"data/locs.RDS\")){\n  locs=wd_raw %&gt;%\n    select(loc) %&gt;% \n    unique() %&gt;% \n    na.omit() %&gt;% \n    mutate(data=purrr::map(loc,get_loc_info)) %&gt;% \n    tidyr::unnest(data)\n  saveRDS(locs, \"data/locs.RDS\")\n}\nlocs=readRDS(\"data/locs.RDS\")\n# summarise which loc_types are sub-categories of human settlement\n\n\nWe then update the data about floods taking into account that supplementary data about locations.\nGet coordinates of countries\nWe also want to get country coordinates\n\n\nCode\nget_country_info=function(country_id){\n  result=spq_init() %&gt;%\n    spq_set(country=country_id) %&gt;% \n    spq_add(\"?country wdt:P625 ?coords_country\") %&gt;%\n    spq_select(-country) %&gt;% \n    spq_perform() \n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/countries.RDS\")){\n  countries=wd_raw %&gt;%\n    select(country) %&gt;% \n    unique() %&gt;% \n    na.omit() %&gt;% \n    mutate(data=purrr::map(country,get_country_info)) %&gt;% \n    tidyr::unnest(data)\n  saveRDS(countries, \"data/countries.RDS\")\n}\ncountries=readRDS(\"data/countries.RDS\")\n\n\nNow we update the data about floods taking into account that supplementary data about countries:\n\n\nCode\nfloodlocs=wd_raw %&gt;%\n  left_join(locs,by=\"loc\",\n            relationship =\"many-to-many\") %&gt;%\n  mutate(country_label=case_when(country_label==\"\"~country_loc_label,\n                                 is.na(country_label)~country_loc_label,\n                                 country_label!=\"\"~country_label)) %&gt;% \n  mutate(country=case_when(is.na(country)~country_loc,\n                           !is.na(country)~country)) %&gt;% \n  mutate(coords_from=case_when(!is.na(coords)~\"flood\",\n                               is.na(coords)~\"location\")) %&gt;% \n  select(flood,flood_label,coords,coords_loc,country,country_label) %&gt;% \n  left_join(countries,by=\"country\",\n            relationship =\"many-to-many\") %&gt;%\n  mutate(coords_from=case_when(is.na(coords) & is.na(coords_loc) & !is.na(coords_country) ~\"3) country\",\n                               !is.na(coords_loc)~\"2) location\",\n                               !is.na(coords)~\"1) not infered: direct\",\n                               TRUE~\"4) no coordinates\")) %&gt;% \n  mutate(coords=case_when(is.na(coords)~coords_loc,\n                          !is.na(coords)~coords)) %&gt;%\n  mutate(coords=case_when(is.na(coords)~coords_country,\n                          !is.na(coords)~coords)) %&gt;% \n  unique()\n\n\nThe coordinates for the flood events are thus inferred from:\n\n\nCode\nfloodlocs %&gt;%\n  group_by(flood,coords_from) %&gt;%\n  summarise(coords_from=unique(coords_from)) %&gt;% \n  ungroup() %&gt;% \n  group_by(coords_from) %&gt;% \n  summarise(n=n())\n\n\n`summarise()` has grouped output by 'flood'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 2\n  coords_from                n\n  &lt;chr&gt;                  &lt;int&gt;\n1 1) not infered: direct    80\n2 2) location              397\n3 3) country               261\n4 4) no coordinates         82"
  },
  {
    "objectID": "index.html#add-images",
    "href": "index.html#add-images",
    "title": "glourb_floods",
    "section": "Add images",
    "text": "Add images\n\n\nCode\nget_images=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?flood wdt:P18 ?image\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform()\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/images.RDS\")){\n  images=wd %&gt;%\n    #sf::st_drop_geometry() %&gt;% \n    select(flood,flood_label) %&gt;% \n    unique() %&gt;% \n    mutate(flood=stringr::str_replace_all(flood,\n                                          \"http://www.wikidata.org/entity/\", \"wd:\")) %&gt;%\n    mutate(images=purrr::map(flood,get_images)) %&gt;% \n    tidyr::unnest(c(images))\n  saveRDS(images, \"data/images.RDS\")\n}\nimages=readRDS(\"data/images.RDS\")"
  },
  {
    "objectID": "index.html#add-categories",
    "href": "index.html#add-categories",
    "title": "glourb_floods",
    "section": "Add categories",
    "text": "Add categories\n\n\nCode\nget_categories=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?flood wdt:P373 ?category\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform()\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/categories.RDS\")){\n  categories=wd %&gt;%\n    #sf::st_drop_geometry() %&gt;% \n    select(flood,flood_label) %&gt;% \n    unique() %&gt;% \n    mutate(flood=stringr::str_replace_all(flood,\n                                          \"http://www.wikidata.org/entity/\", \"wd:\")) %&gt;%\n    mutate(categories=purrr::map(flood,get_categories)) %&gt;% \n    tidyr::unnest(c(categories))\n  saveRDS(categories, \"data/categories.RDS\")\n}\ncategories=readRDS(\"data/categories.RDS\")"
  },
  {
    "objectID": "index.html#join-everything",
    "href": "index.html#join-everything",
    "title": "glourb_floods",
    "section": "Join everything",
    "text": "Join everything\n\n\nCode\nwd_events=wd %&gt;% \n  #sf::st_drop_geometry() %&gt;% \n  select(-date,-date_precision) %&gt;% \n  left_join(dates %&gt;% select(flood,date,date_precision),by=c(\"flood\"),\n            relationship =\"many-to-many\") %&gt;% \n  unique()\nwd_full=wd_events %&gt;% \n  left_join(wikisites,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(images,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(categories,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\")\nwd_events=wd_events %&gt;% select(flood,flood_label,date) %&gt;%\n  mutate(year=lubridate::year(date)) %&gt;% \n  unique()"
  },
  {
    "objectID": "collect_and_curate_wikidata.html",
    "href": "collect_and_curate_wikidata.html",
    "title": "Collect Wikidata about floods",
    "section": "",
    "text": "Code\nlibrary(glitter)\nlibrary(tidyverse)\nlibrary(sequins)\n\n\n\n\nWe query the Wikidata Triplestore through the {glitter} R package (ref).\n\n\nCode\nquery=spq_init() %&gt;%\n    spq_add(\"?flood wdt:P31/wdt:P279* wd:Q8068\") %&gt;% \n    spq_add(\"?flood wdt:P31 ?what\") %&gt;%\n    spq_add(\"?flood wdt:P625 ?coords\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P17 ?country\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P1120 ?deathtoll\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P276 ?loc\",.required=FALSE) %&gt;%\n    spq_label(flood,country,what) \nplot_query(query, labelling=TRUE)\n\n\n\n\n\n\n\nCode\nif(!file.exists(\"data/wd_raw.RDS\")){\n  wd_raw=query %&gt;%\n    spq_perform(replace_prefixes=TRUE) %&gt;% \n    mutate(deathtoll=as.numeric(deathtoll))\n  saveRDS(wd_raw,\"data/wd_raw.RDS\")\n}\nwd_raw=readRDS(\"data/wd_raw.RDS\")\nhead(wd_raw)\n\n\n# A tibble: 6 × 9\n  what     flood    loc   deathtoll country country_label flood_label what_label\n  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;     \n1 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n2 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n3 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n4 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n5 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n6 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n# ℹ 1 more variable: coords &lt;chr&gt;\n\n\nThis table has 1587 rows and documents 804 flood events.\nThe degree of precision in the geographical location for each of these floods might vary. For each recorded flood event we might have access to all or part of these informations:\n\na location (loc) which might refer to a scale as varied as continent/sub-continent, country, basin, city, etc.\na country (country)\nspatial coordinates (coords)\n\nIn case location is not provided, we approximate it with country (if available).\n\n\nCode\nwd_raw=wd_raw %&gt;% \n  mutate(loc=case_when(is.na(loc)~country,\n                       !is.na(loc)~loc))\n\n\n\n\n\nNow we try and complete geographical informations based on Wikidata. For each location identifier, we collect data about\n\ncountry of the location (country_loc)\ncoordinates of the location (coords_loc)\ntype of location (loc_type)\n\n\n\nCode\nget_loc_info=function(loc_id){\n  result=spq_init() %&gt;%\n    spq_set(loc=loc_id) %&gt;% \n    spq_add(\"?loc wdt:P17 ?country_loc\") %&gt;% \n    spq_add(\"?loc wdt:P625 ?coords_loc\") %&gt;% \n    spq_add(\"?loc wdt:P31 ?loc_type\") %&gt;% \n    spq_label(loc, country_loc, loc_type) %&gt;% \n    spq_select(-loc) %&gt;% \n    spq_perform(replace_prefixes=TRUE)\n  result\n}\n\n\nWe apply this query to all locations mentioned in wd_raw:\n\n\nCode\nif(!file.exists(\"data/locs.RDS\")){\n  locs=wd_raw %&gt;%\n    select(loc) %&gt;% \n    unique() %&gt;% \n    na.omit() %&gt;% \n    mutate(data=purrr::map(loc,get_loc_info)) %&gt;% \n    tidyr::unnest(data)\n  saveRDS(locs, \"data/locs.RDS\")\n}\nlocs=readRDS(\"data/locs.RDS\")\n# summarise which loc_types are sub-categories of human settlement\n\n\nWe then update the data about floods taking into account that supplementary data about locations.\nGet coordinates of countries\nWe also want to get country coordinates\n\n\nCode\nget_country_info=function(country_id){\n  result=spq_init() %&gt;%\n    spq_set(country=country_id) %&gt;% \n    spq_add(\"?country wdt:P625 ?coords_country\") %&gt;%\n    spq_select(-country) %&gt;% \n    spq_perform(replace_prefixes=TRUE) \n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/countries.RDS\")){\n  countries=wd_raw %&gt;%\n    select(country) %&gt;% \n    unique() %&gt;% \n    na.omit() %&gt;% \n    mutate(data=purrr::map(country,get_country_info)) %&gt;% \n    tidyr::unnest(data)\n  saveRDS(countries, \"data/countries.RDS\")\n}\ncountries=readRDS(\"data/countries.RDS\")\n\n\nNow we update the data about floods taking into account that supplementary data about countries:\n\n\nCode\nfloodlocs=wd_raw %&gt;%\n  left_join(locs,by=\"loc\",\n            relationship =\"many-to-many\") %&gt;%\n  mutate(country_label=case_when(country_label==\"\"~country_loc_label,\n                                 is.na(country_label)~country_loc_label,\n                                 country_label!=\"\"~country_label)) %&gt;% \n  mutate(country=case_when(is.na(country)~country_loc,\n                           !is.na(country)~country)) %&gt;% \n  mutate(coords_from=case_when(!is.na(coords)~\"flood\",\n                               is.na(coords)~\"location\")) %&gt;% \n  select(flood,flood_label,coords,coords_loc,country,country_label) %&gt;% \n  left_join(countries,by=\"country\",\n            relationship =\"many-to-many\") %&gt;%\n  mutate(coords_from=case_when(is.na(coords) & is.na(coords_loc) & !is.na(coords_country) ~\"3) country\",\n                               !is.na(coords_loc)~\"2) location\",\n                               !is.na(coords)~\"1) direct\",\n                               TRUE~\"4) no coordinates\")) %&gt;% \n  mutate(coords=case_when(is.na(coords)~coords_loc,\n                          !is.na(coords)~coords)) %&gt;%\n  mutate(coords=case_when(is.na(coords)~coords_country,\n                          !is.na(coords)~coords)) %&gt;% \n  unique()\n\n\nThe coordinates for the flood events are thus inferred from:\n\n\nCode\nfloodlocs %&gt;%\n  group_by(flood,coords_from) %&gt;%\n  summarise(coords_from=unique(coords_from),.groups=\"drop\") %&gt;% \n  ungroup() %&gt;% \n  group_by(coords_from) %&gt;% \n  summarise(n=n(),.groups=\"drop\")\n\n\n# A tibble: 4 × 2\n  coords_from           n\n  &lt;chr&gt;             &lt;int&gt;\n1 1) direct            12\n2 2) location         689\n3 3) country           28\n4 4) no coordinates    81\n\n\n\n\n\n\n\nCode\nget_date_info=function(flood_id,type=\"P585\"){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(glue::glue(\"?flood p:{type}/psv:{type} ?datestatement\")) %&gt;% \n    spq_add(\"?datestatement wikibase:timeValue ?datetime\") %&gt;%\n    spq_add(\"?datestatement wikibase:timePrecision ?precision\",.required=FALSE) %&gt;%\n    spq_mutate(date=as.date(datetime)) %&gt;% \n    spq_select(-datestatement,-datetime) %&gt;% \n    spq_perform(replace_prefixes=TRUE)\n  result\n}\n\n\nWe apply this query to all locations mentioned in wd_raw:\n\n\nCode\nfill_void=function(tib,name=\"date\"){\n  if(nrow(tib)==0){\n    tib=tibble::tibble(flood=NA,\n                       date=NA,\n                       precision=NA)\n  }\n  tib=tib %&gt;% select(date, precision)\n  colnames(tib)=c(name,paste0(name,\"_precision\"))\n  return(tib)\n}\nif(!file.exists(\"data/dates.RDS\")){\n  dates=wd_raw %&gt;%\n    select(flood,flood_label)%&gt;% \n    unique() %&gt;%\n    mutate(date=purrr::map(flood,get_date_info)) %&gt;% \n    mutate(start=purrr::map(flood,get_date_info, type=\"P580\")) %&gt;%\n    mutate(end=purrr::map(flood,get_date_info, type=\"P582\")) %&gt;%\n    mutate(date=purrr::map(date,fill_void)) %&gt;% \n    mutate(start=purrr::map(start,fill_void,name=\"start\")) %&gt;% \n    mutate(end=purrr::map(end,fill_void,name=\"end\")) %&gt;% \n    tidyr::unnest(c(date,start,end))\n  saveRDS(dates, \"data/dates.RDS\")\n}\n\n\nThere is a certain heterogeneity in the way information about dates is provided. The flood events’ time of occurrence might be provided through the properties\n\npoint in time (P585)\nstart time (P580)\nend time (P582)\n\nWe infer the date of a flood event in that order of priority\n\nprimarily as the date provided by “point in time” (direct)\nOR by the average date between “start time” and “end time” if they are both provided (start or end),\nOR by start time or end time if only one of them is provided (av_start_end)\nOR by a year provided in flood labels in the form of 4 digits-words if possible (flood_label)\n\n\n\nCode\navdate=function(date1,date2){\n  date1=as.numeric(date1)\n  date2=as.numeric(date2)\n  result=as.Date(mean(c(date1,date2)))\n  return(result)\n}\n\n\n\n\nCode\ndates=readRDS(\"data/dates.RDS\") %&gt;% \n  filter(date_precision&gt;=9|is.na(date_precision)) %&gt;% \n  mutate(date=lubridate::ymd(date),\n         start=lubridate::ymd(start),\n         end=lubridate::ymd(end)) %&gt;%\n  mutate(date_from=case_when(!is.na(date)~\"direct\",\n                            (is.na(date) & !is.na(start) & !is.na(end))~\"av_start_end\",\n                            (is.na(date) & is.na(end) & !is.na(start))~\"start\",\n                            (is.na(date) & is.na(start) & !is.na(end))~\"end\")) %&gt;% \n  mutate(av_start_end=purrr::map2(start,end,avdate)) %&gt;% \n  tidyr::unnest(av_start_end) %&gt;% \n  mutate(date=case_when(!is.na(date)~date,\n                        (is.na(date) & !is.na(start) & !is.na(end))~av_start_end,\n                        (is.na(date) & is.na(end) & !is.na(start))~start,\n                        (is.na(date) & is.na(start) & !is.na(end))~end)) %&gt;% \n  mutate(date_label=stringr::str_extract(flood_label,\"\\\\d{4}\")) %&gt;% \n  mutate(date_label=case_when(!is.na(date_label)~paste0(date_label,\"-01-01\"),\n                              TRUE~NA)) %&gt;% \n  mutate(date_label=case_when(!is.na(date_label)~lubridate::ymd(date_label),\n                              TRUE~NA)) %&gt;% \n  mutate(date_from=case_when((is.na(date) & !is.na(date_label))~\"flood_label\",\n                              TRUE~date_from)) %&gt;% \n  mutate(date_precision=case_when((is.na(date) & !is.na(date_label))~9,\n                              TRUE~date_precision)) %&gt;% \n  mutate(date=case_when((is.na(date) & !is.na(date_label))~date_label,\n                        TRUE~date)) %&gt;% \n  select(-av_start_end)\n\n\n\n\nCode\ndates %&gt;% \n  group_by(date_from) %&gt;% \n  tally()\n\n\n# A tibble: 5 × 2\n  date_from        n\n  &lt;chr&gt;        &lt;int&gt;\n1 av_start_end   145\n2 direct         453\n3 flood_label    138\n4 start           45\n5 &lt;NA&gt;            31\n\n\nJoin to dates and remove geological scale events\n\n\nCode\nwd=wd_raw  %&gt;% \n  select(-coords,-country,-country_label) %&gt;% \n  left_join(floodlocs,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(dates, by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  mutate(year=lubridate::year(date)) \n\n\n\n\n\n\n\nCode\nget_wikisites=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?article schema:about ?flood\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform() %&gt;% \n    filter(stringr::str_detect(article,\"wikipedia\"))\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/wikisites.RDS\")){\n  wikisites=wd %&gt;%\n    select(flood,flood_label) %&gt;% \n    unique() %&gt;%\n    mutate(wikisites=purrr::map(flood,get_wikisites)) %&gt;% \n    tidyr::unnest(c(wikisites))\n  saveRDS(wikisites, \"data/wikisites.RDS\")\n}\nwikisites=readRDS(\"data/wikisites.RDS\")\nwikisites=readRDS(\"data/wikisites_translated.RDS\")\n\n\n\n\n\n\n\nCode\nget_images=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?flood wdt:P18 ?image\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform()\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/images.RDS\")){\n  images=wd %&gt;%\n    select(flood,flood_label) %&gt;% \n    unique() %&gt;% \n    mutate(images=purrr::map(flood,get_images)) %&gt;% \n    tidyr::unnest(c(images))\n  saveRDS(images, \"data/images.RDS\")\n}\nimages=readRDS(\"data/images.RDS\")\n\n\n\n\n\n\n\nCode\nget_categories=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?flood wdt:P373 ?category\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform()\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/categories.RDS\")){\n  categories=wd %&gt;%\n    select(flood,flood_label) %&gt;% \n    unique() %&gt;% \n    mutate(categories=purrr::map(flood,get_categories)) %&gt;% \n    tidyr::unnest(c(categories))\n  saveRDS(categories, \"data/categories.RDS\")\n}\ncategories=readRDS(\"data/categories.RDS\")\n\n\n\n\n\n\n\nCode\nwd_events=wd %&gt;% \n  select(-date,-date_precision) %&gt;% \n  left_join(dates %&gt;% select(flood,date,date_precision),by=c(\"flood\"),\n            relationship =\"many-to-many\") %&gt;% \n  unique()\nwd_full=wd_events %&gt;% \n  left_join(wikisites,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(images,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(categories,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\")\nwd_events=wd_events %&gt;% select(flood,flood_label,date) %&gt;%\n  mutate(year=lubridate::year(date)) %&gt;% \n  unique()\n\nsaveRDS(wd_full,\"data/wd_full.RDS\")\nsaveRDS(wd_events,\"data/wd_events.RDS\")"
  },
  {
    "objectID": "collect_and_curate_wikidata.html#basic-query",
    "href": "collect_and_curate_wikidata.html#basic-query",
    "title": "Collect Wikidata about floods",
    "section": "",
    "text": "We query the Wikidata Triplestore through the {glitter} R package (ref).\n\n\nCode\nquery=spq_init() %&gt;%\n    spq_add(\"?flood wdt:P31/wdt:P279* wd:Q8068\") %&gt;% \n    spq_add(\"?flood wdt:P31 ?what\") %&gt;%\n    spq_add(\"?flood wdt:P625 ?coords\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P17 ?country\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P1120 ?deathtoll\",.required=FALSE) %&gt;%\n    spq_add(\"?flood wdt:P276 ?loc\",.required=FALSE) %&gt;%\n    spq_label(flood,country,what) \nplot_query(query, labelling=TRUE)\n\n\n\n\n\n\n\nCode\nif(!file.exists(\"data/wd_raw.RDS\")){\n  wd_raw=query %&gt;%\n    spq_perform(replace_prefixes=TRUE) %&gt;% \n    mutate(deathtoll=as.numeric(deathtoll))\n  saveRDS(wd_raw,\"data/wd_raw.RDS\")\n}\nwd_raw=readRDS(\"data/wd_raw.RDS\")\nhead(wd_raw)\n\n\n# A tibble: 6 × 9\n  what     flood    loc   deathtoll country country_label flood_label what_label\n  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;     \n1 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n2 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n3 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n4 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n5 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n6 wd:Q8065 wd:Q146… wd:Q…        85 wd:Q148 People's Rep… 2013 China… natural d…\n# ℹ 1 more variable: coords &lt;chr&gt;\n\n\nThis table has 1587 rows and documents 804 flood events.\nThe degree of precision in the geographical location for each of these floods might vary. For each recorded flood event we might have access to all or part of these informations:\n\na location (loc) which might refer to a scale as varied as continent/sub-continent, country, basin, city, etc.\na country (country)\nspatial coordinates (coords)\n\nIn case location is not provided, we approximate it with country (if available).\n\n\nCode\nwd_raw=wd_raw %&gt;% \n  mutate(loc=case_when(is.na(loc)~country,\n                       !is.na(loc)~loc))"
  },
  {
    "objectID": "collect_and_curate_wikidata.html#add-coordinates",
    "href": "collect_and_curate_wikidata.html#add-coordinates",
    "title": "Collect Wikidata about floods",
    "section": "",
    "text": "Now we try and complete geographical informations based on Wikidata. For each location identifier, we collect data about\n\ncountry of the location (country_loc)\ncoordinates of the location (coords_loc)\ntype of location (loc_type)\n\n\n\nCode\nget_loc_info=function(loc_id){\n  result=spq_init() %&gt;%\n    spq_set(loc=loc_id) %&gt;% \n    spq_add(\"?loc wdt:P17 ?country_loc\") %&gt;% \n    spq_add(\"?loc wdt:P625 ?coords_loc\") %&gt;% \n    spq_add(\"?loc wdt:P31 ?loc_type\") %&gt;% \n    spq_label(loc, country_loc, loc_type) %&gt;% \n    spq_select(-loc) %&gt;% \n    spq_perform(replace_prefixes=TRUE)\n  result\n}\n\n\nWe apply this query to all locations mentioned in wd_raw:\n\n\nCode\nif(!file.exists(\"data/locs.RDS\")){\n  locs=wd_raw %&gt;%\n    select(loc) %&gt;% \n    unique() %&gt;% \n    na.omit() %&gt;% \n    mutate(data=purrr::map(loc,get_loc_info)) %&gt;% \n    tidyr::unnest(data)\n  saveRDS(locs, \"data/locs.RDS\")\n}\nlocs=readRDS(\"data/locs.RDS\")\n# summarise which loc_types are sub-categories of human settlement\n\n\nWe then update the data about floods taking into account that supplementary data about locations.\nGet coordinates of countries\nWe also want to get country coordinates\n\n\nCode\nget_country_info=function(country_id){\n  result=spq_init() %&gt;%\n    spq_set(country=country_id) %&gt;% \n    spq_add(\"?country wdt:P625 ?coords_country\") %&gt;%\n    spq_select(-country) %&gt;% \n    spq_perform(replace_prefixes=TRUE) \n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/countries.RDS\")){\n  countries=wd_raw %&gt;%\n    select(country) %&gt;% \n    unique() %&gt;% \n    na.omit() %&gt;% \n    mutate(data=purrr::map(country,get_country_info)) %&gt;% \n    tidyr::unnest(data)\n  saveRDS(countries, \"data/countries.RDS\")\n}\ncountries=readRDS(\"data/countries.RDS\")\n\n\nNow we update the data about floods taking into account that supplementary data about countries:\n\n\nCode\nfloodlocs=wd_raw %&gt;%\n  left_join(locs,by=\"loc\",\n            relationship =\"many-to-many\") %&gt;%\n  mutate(country_label=case_when(country_label==\"\"~country_loc_label,\n                                 is.na(country_label)~country_loc_label,\n                                 country_label!=\"\"~country_label)) %&gt;% \n  mutate(country=case_when(is.na(country)~country_loc,\n                           !is.na(country)~country)) %&gt;% \n  mutate(coords_from=case_when(!is.na(coords)~\"flood\",\n                               is.na(coords)~\"location\")) %&gt;% \n  select(flood,flood_label,coords,coords_loc,country,country_label) %&gt;% \n  left_join(countries,by=\"country\",\n            relationship =\"many-to-many\") %&gt;%\n  mutate(coords_from=case_when(is.na(coords) & is.na(coords_loc) & !is.na(coords_country) ~\"3) country\",\n                               !is.na(coords_loc)~\"2) location\",\n                               !is.na(coords)~\"1) direct\",\n                               TRUE~\"4) no coordinates\")) %&gt;% \n  mutate(coords=case_when(is.na(coords)~coords_loc,\n                          !is.na(coords)~coords)) %&gt;%\n  mutate(coords=case_when(is.na(coords)~coords_country,\n                          !is.na(coords)~coords)) %&gt;% \n  unique()\n\n\nThe coordinates for the flood events are thus inferred from:\n\n\nCode\nfloodlocs %&gt;%\n  group_by(flood,coords_from) %&gt;%\n  summarise(coords_from=unique(coords_from),.groups=\"drop\") %&gt;% \n  ungroup() %&gt;% \n  group_by(coords_from) %&gt;% \n  summarise(n=n(),.groups=\"drop\")\n\n\n# A tibble: 4 × 2\n  coords_from           n\n  &lt;chr&gt;             &lt;int&gt;\n1 1) direct            12\n2 2) location         689\n3 3) country           28\n4 4) no coordinates    81"
  },
  {
    "objectID": "collect_and_curate_wikidata.html#get-and-clean-dates",
    "href": "collect_and_curate_wikidata.html#get-and-clean-dates",
    "title": "Collect Wikidata about floods",
    "section": "",
    "text": "Code\nget_date_info=function(flood_id,type=\"P585\"){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(glue::glue(\"?flood p:{type}/psv:{type} ?datestatement\")) %&gt;% \n    spq_add(\"?datestatement wikibase:timeValue ?datetime\") %&gt;%\n    spq_add(\"?datestatement wikibase:timePrecision ?precision\",.required=FALSE) %&gt;%\n    spq_mutate(date=as.date(datetime)) %&gt;% \n    spq_select(-datestatement,-datetime) %&gt;% \n    spq_perform(replace_prefixes=TRUE)\n  result\n}\n\n\nWe apply this query to all locations mentioned in wd_raw:\n\n\nCode\nfill_void=function(tib,name=\"date\"){\n  if(nrow(tib)==0){\n    tib=tibble::tibble(flood=NA,\n                       date=NA,\n                       precision=NA)\n  }\n  tib=tib %&gt;% select(date, precision)\n  colnames(tib)=c(name,paste0(name,\"_precision\"))\n  return(tib)\n}\nif(!file.exists(\"data/dates.RDS\")){\n  dates=wd_raw %&gt;%\n    select(flood,flood_label)%&gt;% \n    unique() %&gt;%\n    mutate(date=purrr::map(flood,get_date_info)) %&gt;% \n    mutate(start=purrr::map(flood,get_date_info, type=\"P580\")) %&gt;%\n    mutate(end=purrr::map(flood,get_date_info, type=\"P582\")) %&gt;%\n    mutate(date=purrr::map(date,fill_void)) %&gt;% \n    mutate(start=purrr::map(start,fill_void,name=\"start\")) %&gt;% \n    mutate(end=purrr::map(end,fill_void,name=\"end\")) %&gt;% \n    tidyr::unnest(c(date,start,end))\n  saveRDS(dates, \"data/dates.RDS\")\n}\n\n\nThere is a certain heterogeneity in the way information about dates is provided. The flood events’ time of occurrence might be provided through the properties\n\npoint in time (P585)\nstart time (P580)\nend time (P582)\n\nWe infer the date of a flood event in that order of priority\n\nprimarily as the date provided by “point in time” (direct)\nOR by the average date between “start time” and “end time” if they are both provided (start or end),\nOR by start time or end time if only one of them is provided (av_start_end)\nOR by a year provided in flood labels in the form of 4 digits-words if possible (flood_label)\n\n\n\nCode\navdate=function(date1,date2){\n  date1=as.numeric(date1)\n  date2=as.numeric(date2)\n  result=as.Date(mean(c(date1,date2)))\n  return(result)\n}\n\n\n\n\nCode\ndates=readRDS(\"data/dates.RDS\") %&gt;% \n  filter(date_precision&gt;=9|is.na(date_precision)) %&gt;% \n  mutate(date=lubridate::ymd(date),\n         start=lubridate::ymd(start),\n         end=lubridate::ymd(end)) %&gt;%\n  mutate(date_from=case_when(!is.na(date)~\"direct\",\n                            (is.na(date) & !is.na(start) & !is.na(end))~\"av_start_end\",\n                            (is.na(date) & is.na(end) & !is.na(start))~\"start\",\n                            (is.na(date) & is.na(start) & !is.na(end))~\"end\")) %&gt;% \n  mutate(av_start_end=purrr::map2(start,end,avdate)) %&gt;% \n  tidyr::unnest(av_start_end) %&gt;% \n  mutate(date=case_when(!is.na(date)~date,\n                        (is.na(date) & !is.na(start) & !is.na(end))~av_start_end,\n                        (is.na(date) & is.na(end) & !is.na(start))~start,\n                        (is.na(date) & is.na(start) & !is.na(end))~end)) %&gt;% \n  mutate(date_label=stringr::str_extract(flood_label,\"\\\\d{4}\")) %&gt;% \n  mutate(date_label=case_when(!is.na(date_label)~paste0(date_label,\"-01-01\"),\n                              TRUE~NA)) %&gt;% \n  mutate(date_label=case_when(!is.na(date_label)~lubridate::ymd(date_label),\n                              TRUE~NA)) %&gt;% \n  mutate(date_from=case_when((is.na(date) & !is.na(date_label))~\"flood_label\",\n                              TRUE~date_from)) %&gt;% \n  mutate(date_precision=case_when((is.na(date) & !is.na(date_label))~9,\n                              TRUE~date_precision)) %&gt;% \n  mutate(date=case_when((is.na(date) & !is.na(date_label))~date_label,\n                        TRUE~date)) %&gt;% \n  select(-av_start_end)\n\n\n\n\nCode\ndates %&gt;% \n  group_by(date_from) %&gt;% \n  tally()\n\n\n# A tibble: 5 × 2\n  date_from        n\n  &lt;chr&gt;        &lt;int&gt;\n1 av_start_end   145\n2 direct         453\n3 flood_label    138\n4 start           45\n5 &lt;NA&gt;            31\n\n\nJoin to dates and remove geological scale events\n\n\nCode\nwd=wd_raw  %&gt;% \n  select(-coords,-country,-country_label) %&gt;% \n  left_join(floodlocs,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(dates, by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  mutate(year=lubridate::year(date))"
  },
  {
    "objectID": "collect_and_curate_wikidata.html#add-wiki-sites",
    "href": "collect_and_curate_wikidata.html#add-wiki-sites",
    "title": "Collect Wikidata about floods",
    "section": "",
    "text": "Code\nget_wikisites=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?article schema:about ?flood\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform() %&gt;% \n    filter(stringr::str_detect(article,\"wikipedia\"))\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/wikisites.RDS\")){\n  wikisites=wd %&gt;%\n    select(flood,flood_label) %&gt;% \n    unique() %&gt;%\n    mutate(wikisites=purrr::map(flood,get_wikisites)) %&gt;% \n    tidyr::unnest(c(wikisites))\n  saveRDS(wikisites, \"data/wikisites.RDS\")\n}\nwikisites=readRDS(\"data/wikisites.RDS\")\nwikisites=readRDS(\"data/wikisites_translated.RDS\")"
  },
  {
    "objectID": "collect_and_curate_wikidata.html#add-images",
    "href": "collect_and_curate_wikidata.html#add-images",
    "title": "Collect Wikidata about floods",
    "section": "",
    "text": "Code\nget_images=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?flood wdt:P18 ?image\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform()\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/images.RDS\")){\n  images=wd %&gt;%\n    select(flood,flood_label) %&gt;% \n    unique() %&gt;% \n    mutate(images=purrr::map(flood,get_images)) %&gt;% \n    tidyr::unnest(c(images))\n  saveRDS(images, \"data/images.RDS\")\n}\nimages=readRDS(\"data/images.RDS\")"
  },
  {
    "objectID": "collect_and_curate_wikidata.html#add-categories",
    "href": "collect_and_curate_wikidata.html#add-categories",
    "title": "Collect Wikidata about floods",
    "section": "",
    "text": "Code\nget_categories=function(flood_id){\n  result=spq_init() %&gt;%\n    spq_set(flood=flood_id) %&gt;% \n    spq_add(\"?flood wdt:P373 ?category\") %&gt;%  \n    spq_select(-flood) %&gt;% \n    spq_perform()\n  result\n}\n\n\n\n\nCode\nif(!file.exists(\"data/categories.RDS\")){\n  categories=wd %&gt;%\n    select(flood,flood_label) %&gt;% \n    unique() %&gt;% \n    mutate(categories=purrr::map(flood,get_categories)) %&gt;% \n    tidyr::unnest(c(categories))\n  saveRDS(categories, \"data/categories.RDS\")\n}\ncategories=readRDS(\"data/categories.RDS\")"
  },
  {
    "objectID": "collect_and_curate_wikidata.html#join-everything",
    "href": "collect_and_curate_wikidata.html#join-everything",
    "title": "Collect Wikidata about floods",
    "section": "",
    "text": "Code\nwd_events=wd %&gt;% \n  select(-date,-date_precision) %&gt;% \n  left_join(dates %&gt;% select(flood,date,date_precision),by=c(\"flood\"),\n            relationship =\"many-to-many\") %&gt;% \n  unique()\nwd_full=wd_events %&gt;% \n  left_join(wikisites,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(images,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\") %&gt;% \n  left_join(categories,by=c(\"flood\",\"flood_label\"),\n            relationship =\"many-to-many\")\nwd_events=wd_events %&gt;% select(flood,flood_label,date) %&gt;%\n  mutate(year=lubridate::year(date)) %&gt;% \n  unique()\n\nsaveRDS(wd_full,\"data/wd_full.RDS\")\nsaveRDS(wd_events,\"data/wd_events.RDS\")"
  },
  {
    "objectID": "index.html#digital-humanities-quarterly-scope",
    "href": "index.html#digital-humanities-quarterly-scope",
    "title": "General purpose",
    "section": "",
    "text": "Open Access Journal. The journal’s scope includes but is not limited to:\n\nDigital Tools and Methods in Humanities Research: DHQ publishes articles that showcase innovative digital tools, methods, and approaches used in humanities scholarship. This can involve text analysis, data visualization, digital archives, GIS (Geographic Information Systems), network analysis, and more.\nCritical Assessment of Digital Technologies in Humanities Studies: DHQ features critical evaluations and discussions about the implications, challenges, and limitations of using digital technologies in humanities research. This includes considerations of ethics, accessibility, and cultural implications of digital humanities work.\nInterdisciplinary Collaborations: The journal promotes interdisciplinary collaborations by highlighting research at the intersection of humanities disciplines and technology. It covers collaborations between historians, literary scholars, linguists, cultural studies scholars, and experts in computer science, data science, and information technology.\nDigital Pedagogy and Teaching Approaches: DHQ discusses innovative pedagogical approaches that integrate digital tools and methods into humanities teaching. This includes case studies, reviews, and discussions on the use of technology in the classroom to enhance learning experiences.\nDigital Humanities Projects and Case Studies: The journal publishes case studies and reports on digital humanities projects, initiatives, and experiments, providing insights into the practical application of digital methods in various humanities fields.\nOpen Access and Open Data: DHQ supports open access and open data principles, often discussing issues related to data curation, preservation, and accessibility in the context of digital humanities research."
  },
  {
    "objectID": "index.html#basic-stats",
    "href": "index.html#basic-stats",
    "title": "General purpose",
    "section": "Basic stats",
    "text": "Basic stats\n\n\nCode\nwd_events=readRDS(\"data/wd_events.RDS\")\nwd_full=readRDS(\"data/wd_full.RDS\")\nNwd=wd_events %&gt;% nrow()\nNaft1900=wd_events %&gt;% filter(year&gt;=1900) %&gt;% nrow()\nNaft2000=wd_events %&gt;% filter(year&gt;=2000) %&gt;% nrow()\nPropaft1900=Naft1900/Nwd\nPropaft2000=Naft2000/Nwd\n\n\nOur Wikidata base documents 814 flood events, 0.7555283% of which occurred after 1900 and 0.5208845% of which occurred after 2000.\n\n\nCode\nwd_events_freq=wd_events %&gt;% \n  mutate(cat_year=cut(year,breaks=c(1000,1200,1400,1600,1800,\n                                    2000,2023),dig.lab=10)) %&gt;% \n  group_by(cat_year) %&gt;% tally()\np1=ggplot(wd_events_freq, aes(x=cat_year,y=n))+\n  geom_col()\np2=ggplot(wd_events %&gt;% filter(year&gt;=2000), aes(x=year))+\n  geom_histogram(breaks=2000:2023)\nfigure &lt;- ggarrange(p1,p2,\n                    labels = c(\"A\", \"B\"),\n                    ncol = 1, nrow = 2)\nfigure\n\n\n\n\n\nFigure 1: Distribution of flood events through time A) all events dated with a year-accuracy B) events dated with a year-accuracy starting in 2000"
  },
  {
    "objectID": "index.html#intro",
    "href": "index.html#intro",
    "title": "General purpose",
    "section": "",
    "text": "Sekajugo et al. (2022) explores the interest of citizen science for collecting data about floods, at a regional scale."
  },
  {
    "objectID": "index.html#map",
    "href": "index.html#map",
    "title": "General purpose",
    "section": "Map",
    "text": "Map\n\n\nCode\nlibrary(leaflet) \n wd_map=wd_full %&gt;%\n  # filter NA coords before transforming in sf multipoint\n  filter(!is.na(coords)) %&gt;%\n  sf::st_as_sf(wkt=\"coords\") %&gt;% \n  # group by flood event\n  group_by(flood,flood_label) %&gt;%\n  # in case there is no Wikipedia article \n  mutate(noarticle=all(is.na(article)),\n         noimage=all(is.na(image)),\n         lang=stringr::str_extract(article,\"..(?=\\\\.wikipedia)\"),\n         flood=stringr::str_replace(flood,\"wd:\",\"\")) %&gt;% \n  mutate(article=case_when(noarticle~\"\",\n                           !noarticle~glue::glue(\"&lt;a href='{article}',target='_blank'&gt;{lang} 🔗 &lt;/a&gt;\")),\n         image=case_when(noimage~\"\",\n                         !noimage~glue::glue(\"&lt;img src='{image}'  width='200'&gt;\"))) %&gt;% \n  summarise(coords_from=first(coords_from),\n            year=first(year),\n            country_label=first(country_label),\n            deathtoll=mean(deathtoll,na.rm=TRUE),\n            date=first(date),\n            start=first(start),\n            end=first(end),\n            date_precision=first(date_precision),\n            article=paste0(unique(article), collapse=\" \"),\n            image=paste0(unique(image),collapse=\" \")) %&gt;% \n  ungroup() %&gt;% \n  mutate(popup=glue::glue(\"&lt;h1&gt;{flood_label}&lt;a href='http://www.wikidata.org/entity/{flood}'\n                             target='_blank'&gt;🔗&lt;/a&gt;&lt;/h1&gt;\")) %&gt;%\n  mutate(popup=case_when(!is.na(date)~glue::glue(\"{popup}&lt;p&gt;date: {date}&lt;/p&gt;\"),\n                                 TRUE~popup)) %&gt;% \n  mutate(popup=case_when(!is.na(deathtoll)~glue::glue(\"{popup}&lt;p&gt;deathtoll:{deathtoll}&lt;/p&gt;\"),\n                                 TRUE~popup)) %&gt;% \n  mutate(popup=case_when(!is.na(article)~glue::glue(\"{popup}&lt;p&gt;{article}&lt;/p&gt;\"),\n                                 TRUE~popup)) %&gt;% \n  mutate(popup=case_when(!is.na(image)~glue::glue(\"{popup}&lt;p&gt;{image}&lt;/p&gt;\"),\n                                 TRUE~popup)) %&gt;% \n  sf::st_centroid()\ncoords=wd_map %&gt;%\n  sf::st_coordinates() %&gt;% \n  as_tibble() %&gt;% \n  select(long=X,lat=Y)\nwd_map=wd_map %&gt;% \n  bind_cols(coords) %&gt;% \n  mutate(coords_txt=as.character(coords))\n\n\n\n\nCode\njitter_coord=function(datlonlat,n){\n  long=datlonlat$long+runif(n,-1,1)\n  lat=datlonlat$lat+runif(n,-1,1)\n  result=tibble::tibble(flood=datlonlat$flood,\n                           long=long,\n                           lat=lat)\n  return(result)\n}\n\n\n\n\nCode\njittered_coords=wd_map  %&gt;% \n  sf::st_drop_geometry() %&gt;% \n  select(flood,coords_txt,long,lat) %&gt;% \n  unique() %&gt;% \n  group_by(coords_txt) %&gt;%\n  mutate(n=n()) %&gt;%\n  tidyr::nest(data=c(flood,long,lat)) %&gt;%\n  mutate(data=purrr::map2(data,n,jitter_coord)) %&gt;%\n  tidyr::unnest(data) %&gt;%\n  ungroup()\n\n\n\n\nCode\nwd_map=wd_map %&gt;%\n  sf::st_drop_geometry() %&gt;% \n  select(-long,-lat,-coords_txt) %&gt;% \n  left_join(jittered_coords %&gt;%\n              select(flood,long,lat),\n            by=\"flood\") %&gt;% \n  sf::st_as_sf(coords = c(\"long\", \"lat\"), \n               crs = 4326, agr = \"constant\")\n\n\n\n\nCode\n# Définition d'une échelle colorée \n# (en fonction de date de sortie) \npal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"),\n                    c(1648,1900,1950,1980,2000,2010,2023)) \n# Création de la carte \nleaf_wd_map=leaflet(wd_map) %&gt;% # déf carte \n  addProviderTiles(providers$Esri.NatGeoWorldMap) %&gt;% # ajout fond de carte\n  addCircleMarkers(col=~pal(year),\n                   popup = ~popup,\n                   radius =~log(deathtoll+2)\n                   ) \n\n\nWarning in pal(year): Some values were outside the color scale and will be\ntreated as NA\n\nWarning in pal(year): Some values were outside the color scale and will be\ntreated as NA\n\n\n\n\nCode\nleaf_wd_map"
  },
  {
    "objectID": "index.html#data-from-the-dartmouth-flood-observatory",
    "href": "index.html#data-from-the-dartmouth-flood-observatory",
    "title": "General purpose",
    "section": "Data from the Dartmouth Flood Observatory",
    "text": "Data from the Dartmouth Flood Observatory\n\n\nCode\navdate=function(date1,date2){\n  date1=as.numeric(date1)\n  date2=as.numeric(date2)\n  result=as.Date(mean(c(date1,date2)))\n  return(result)\n}\n\n\n\n\nCode\ndfo_raw &lt;- readr::read_csv(\"data/FloodArchive.csv\", \n    locale = locale(decimal_mark = \",\"))\ncolnames(dfo_raw)=c(\"index\",\"GlideNumber\",\"dfo_country\",\"dfo_other_country\",\n           \"dfo_centroid_x\",\"dfo_centroid_y\",\"area\",\"dfo_began\",\"dfo_ended\",\n           \"validation\",\"dfo_dead\",\"displaced\",\"maincause\",\"severity\")\ndfo_raw=dfo_raw %&gt;% \n  mutate(start=lubridate::dmy(dfo_began),\n         end=lubridate::dmy(dfo_ended)) %&gt;% \n  mutate(dfo_other_country=case_when(is.na(dfo_other_country)~\"\",\n                                     dfo_other_country==0~\"\",\n                                     TRUE~dfo_other_country)) %&gt;% \n  mutate(flood=as.character(index),\n         flood_label=as.character(index),\n         country_label=paste(dfo_country,\" \",dfo_other_country),\n         deathtoll=dfo_dead,\n         coords=paste0(\"Point(\",dfo_centroid_x,\" \",dfo_centroid_y,\")\"))\ndfo_comp=dfo_raw %&gt;% \n  select(flood,flood_label,country_label,deathtoll, start, end,coords) %&gt;% \n  mutate(date=purrr::map2(start,end,avdate)) %&gt;% \n  tidyr::unnest(date)\n\n\n\n\nCode\ncoords_wd_map=sf::st_coordinates(wd_map) %&gt;%\n  as_tibble() %&gt;%\n  mutate(coords=glue::glue(\"Point({X} {Y})\")) %&gt;%\n  pull(coords)\nwd_comp=wd_map %&gt;%\n  sf::st_drop_geometry() %&gt;% \n  mutate(coords=coords_wd_map) %&gt;% \n  select(flood,flood_label,country_label,deathtoll, date ,start, end,coords,popup) %&gt;% \n  mutate(flood=stringr::str_replace(flood,\"wd:\",\"\"))\n\n\nThis dataset documents 5130 flood events that occurred between 1985-01-01 and 2021-10-09.\n\n\nCode\nNwd_in_range=wd_events %&gt;% \n  filter(year&gt;=1985 & year&lt;=2021) %&gt;% \n  sf::st_drop_geometry() %&gt;%\n  summarise(n=length(unique(flood))) %&gt;% \n  pull(n)\n\n\nBased on the dates of observations for the dfo data base, 417 out of the 814 flood events in our Wikidata base might fall into it."
  },
  {
    "objectID": "index.html#basic-stats-1",
    "href": "index.html#basic-stats-1",
    "title": "General purpose",
    "section": "Basic stats",
    "text": "Basic stats\n\n\nCode\nwd_comp=wd_comp  %&gt;% \n   mutate(source=\"wd\") %&gt;% \n   mutate(flood=paste0(\"wd:\",flood)) %&gt;% \n   sf::st_drop_geometry() %&gt;% \n   filter(date&gt;lubridate::ymd(\"1985-01-01\") & \n          date&lt;lubridate::ymd(\"2021-12-31\")) \ndfo_comp=dfo_comp %&gt;%\n   mutate(source=\"dfo\") %&gt;%\n   mutate(popup=glue::glue(\"&lt;h1&gt;{flood_label}&lt;/h1&gt;\n                            &lt;p&gt;date: {date}&lt;/p&gt;\n                            &lt;p&gt;deathtoll:{deathtoll}&lt;/p&gt;\"))  \ntib=bind_rows(wd_comp,dfo_comp) %&gt;% \n  mutate(date=lubridate::round_date(date,\"month\")) %&gt;% \n   sf::st_as_sf(wkt=\"coords\")\n\n\nBased on the spatial and temporal data in both datasets, we try to find correspondences between the events described in Wikidata and those described in the Dartmouth Flood Observatory.\n\n\nCode\n# tib %&gt;% \n#   sf::st_transform(crs=\"\")\n\nfind_corresponding_flood=function(flood_id,tib){\n  tib_sub=tib %&gt;% filter(flood==flood_id)\n  tib_dist=tib %&gt;% \n    mutate(disttime=abs(tib$date-tib_sub$date),\n           distspace=sf::st_distance(tib,tib_sub)[,1]) %&gt;% \n    filter(flood!=flood_id) %&gt;%  \n    filter(disttime==min(disttime)|distspace==min(distspace)) %&gt;% \n    filter(disttime&lt;60 & distspace&lt;2) %&gt;%\n    select(floodcorr=flood,\n           disttime,\n           distspace,\n           sourcecorr=source,\n           country_corr=country_label,\n           deathtoll_corr=deathtoll) %&gt;% \n    sf::st_drop_geometry()\n  if(nrow(tib_dist)==0){\n    tib_dist=tibble::tibble(floodcorr=NA,\n                            disttime=NA,\n                            distspace=NA,\n                            sourcecorr=NA,\n                            countrycorr=NA,\n                            deathtollcorr=NA)\n  }\n  return(tib_dist)\n}\n\n\n\n\nCode\nif(!file.exists(\"data/tibcorr.RDS\")){\ntibcorr= tib %&gt;% \n  mutate(data=purrr::map(flood,find_corresponding_flood,tib=tib)) %&gt;% \n  tidyr::unnest(data) %&gt;% \n  filter(source==\"wd\" & sourcecorr==\"dfo\")\nsaveRDS(tibcorr,\n        \"data/tibcorr.RDS\")\n}\n\n\n\n\nCode\ntib=sf::st_as_sf(tib,wkt=\"coords\")\ntibcorr=readRDS(\"data/tibcorr.RDS\") %&gt;% \n  sf::st_drop_geometry()\njoined_events=bind_rows(tibble::tibble(id=1:nrow(tibcorr),flood=tibcorr$flood),\n               tibble::tibble(id=1:nrow(tibcorr),flood=tibcorr$floodcorr))\njoined_events=tib %&gt;% \n  left_join(joined_events, by=\"flood\") %&gt;%  \n  select(id,flood) %&gt;% \n  group_by(id) %&gt;% \n  summarise(m =mean(id),do_union=FALSE) %&gt;% \n  sf::st_cast(\"LINESTRING\")\njoined_events=joined_events[1:(nrow(joined_events)-1),]"
  },
  {
    "objectID": "use_wikipedia.html",
    "href": "use_wikipedia.html",
    "title": "Use Wikipedia to complete Wikidata",
    "section": "",
    "text": "Use Wikipedia to complete Wikidata\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nCode\nif(!file.exists(\"data/wikisites_translated.RDS\")){\n  wikisites=readRDS(\"data/wikisites.RDS\") %&gt;% \n     mutate(lang=stringr::str_extract(article,\"(?&lt;=https://)[[:alpha:]]{2}\"))%&gt;% \n     mutate(title=stringr::str_extract(article,\"(?&lt;=\\\\/wiki\\\\/).*\")) %&gt;% \n     mutate(title=purrr::map_chr(title,URLdecode)) %&gt;% \n     mutate(title=stringr::str_replace_all(title,\"_\",\" \")) %&gt;% \n     mutate(translated_title=purrr::map2(title,lang,\n                                         ~safely(polyglotr::google_translate)(.x,,source_language=.y,target_language=\"en\"))) %&gt;% \n    mutate(translated_title=purrr::map(translated_title,\n                                       ~.$result)) %&gt;%\n    mutate(translated_title=purrr::map_chr(translated_title,\n                                           ~replace(.x,is.null(.x),NA)))\n  saveRDS(wikisites,\"data/wikisites_translated.RDS\")\n}\nwikisites=readRDS(\"data/wikisites_translated.RDS\")\n\n\n\n\nCode\nif(!file.exists(\"data/wikisites_text.RDS\")){\n  library(rvest)\n  # Get text paragraphs from all Wikipedia articles\n  wikisites_text=wikisites %&gt;%\n    mutate(html=purrr::map(article,read_html)) %&gt;% \n    mutate(html=purrr::map(html,~html_nodes(.x,\"p\"))) %&gt;%\n    mutate(text=purrr::map(html,html_text)) %&gt;% \n    mutate(text=purrr::map(text,~paste0(.x,collapse=\"\"))) %&gt;%\n    mutate(text=purrr::map(text,~str_replace_all(.x,\"\\\\[\\\\d*\\\\]\",\"\")))\n  # Translate them all to English with Google Translate (if possible)\n  wikisites_text=wikisites_text %&gt;% \n    mutate(textt=purrr::map2(text,lang,\n                            ~safely(polyglotr::google_translate)(.x,\n                                                                 source_language=.y,\n                                                                 target_language=\"en\"))) %&gt;% \n    mutate(error=purrr::map(textt,\"error\")) %&gt;% \n    mutate(textt=purrr::map(textt,\"result\")) %&gt;% \n    mutate(textt=purrr::map_chr(textt,\n                               ~replace(.x,is.null(.x),NA))) \nsaveRDS(wikisites_text,\"data/wikisites_text.RDS\")\n}\n\n# text=text %&gt;% \n#   mutate(dead=purrr::map(textt,\n#                          ~unlist(stringr::str_extract_all(.x,\n#     \"[\\\\d\\\\.\\\\,]+\\\\s(dead|victims)\"))))\n\n\n\n\nCode\n# lexicon_en=mixr::get_lexicon(\"en\")\n# words=wikisites_text %&gt;% \n#   tidytext::unnest_tokens(output=\"word\",input=\"textt\",token=\"words\") %&gt;% \n#   left_join(lexicon_en,by=c(\"word\")) %&gt;% \n#   filter(type!=\"sw\" & lemma!=\"flood\") %&gt;% \n#   group_by(flood,flood_label,lemma) %&gt;% \n#   summarise(n=n()) %&gt;% \n#   arrange(flood,flood_label,desc(n)) %&gt;% \n#   slice_head(n=20) %&gt;%\n#   ungroup() %&gt;% \n#   group_by(flood,flood_label) %&gt;% \n#   summarise(words=paste(lemma,collapse=\"; \"))"
  },
  {
    "objectID": "index.html#participatory-local-data-about-floods",
    "href": "index.html#participatory-local-data-about-floods",
    "title": "General purpose",
    "section": "Participatory local data about floods",
    "text": "Participatory local data about floods\nParticipatory data collection holds significant potential in enhancing the understanding and management of flood events. This approach involves engaging local communities, citizens, and grassroots organizations in the collection, analysis, and sharing of data related to flood occurrences. Examples of such initiatives show the potential of participatory data to complement institutional data about floods at a local scale Sekajugo et al. (2022). By incorporating local knowledge, experiences, and observations, participatory methods complement traditional data sources, offering valuable insights into flood-prone areas that might be overlooked by centralized or remote monitoring systems. More broadly, volunteered geographical data at a local scale has been shown to be a valuable source of data regarding natural hazards.\nCommunities living in flood-prone regions possess unique, context-specific knowledge about local environmental changes, historical flood patterns, vulnerable areas, and coping mechanisms. Engaging these communities in data collection through citizen science initiatives, mobile applications, community mapping, or participatory workshops allows for the collection of granular, real-time information that supplements existing datasets. This bottom-up approach not only enhances the accuracy and granularity of flood data but also fosters community empowerment, resilience-building, and local capacity development.\nMoreover, participatory data can bridge gaps in official reporting by capturing small-scale or localized flood events that might not meet the threshold for formal reporting. Integrating participatory data with conventional datasets enables a more comprehensive understanding of flood dynamics, aiding in the development of effective early warning systems, disaster response plans, and mitigation strategies.\nHowever, challenges such as ensuring data accuracy, reliability, and standardization persist in participatory approaches. Establishing protocols for data validation, quality control, and harmonization between participatory and formal datasets is crucial to maximize the potential of participatory data while maintaining data integrity (Senaratne et al. 2017). The stakes around data validation and homogeneization are particularly high in the prospect of studying floods at a large (or even global) scale.\nOverall, leveraging participatory data in conjunction with conventional methods has the potential to enrich global flood databases, improve resilience, and empower communities to better respond to and mitigate the impacts of flood events. This collaborative approach can contribute significantly to more holistic and inclusive strategies for managing floods worldwide."
  },
  {
    "objectID": "index.html#institutional-global-data-about-floods",
    "href": "index.html#institutional-global-data-about-floods",
    "title": "General purpose",
    "section": "Institutional global data about floods",
    "text": "Institutional global data about floods\nThe Dartmouth Flood Observatory (DFO) is a research group specializing in the collection and analysis of global flood data. Combining remote sensing and news reports’ analysis, the DFO produces detailed information on the extent, frequency, and impacts of floods worldwide (Kundzewicz, Pińskwar, and Brakenridge 2013). It constitutes an invaluable source of information on the subject, used in many scientific studies on flood events.\nIn parallel to that kind of research-related, expert database on the subject, the Wikimedia project stands as a remarkable source of structured or semi-structured participatory data with its vast array of user-generated content across platforms like Wikipedia, Wikidata, and Wikimedia Commons. Wikipedia, being one of the largest collaborative encyclopedias globally, harnesses the collective knowledge of volunteers worldwide who contribute, edit, and curate articles on diverse subjects, including geographical features, history, and environmental events such as floods. Wikidata, an open database, provides structured data that can be used to categorize and link information, potentially cataloging flood events, affected regions, and relevant details. Wikimedia Commons serves as a repository for multimedia files, housing images, maps, and other visual resources related to floods, contributing to a more comprehensive understanding of such events. The open nature of Wikimedia projects allows for continual updates and contributions, making it a valuable resource for researchers, policymakers, and the public seeking semi-structured participatory data on various topics, including flood events, across the globe."
  },
  {
    "objectID": "index.html#how-does-wikidata-provide-unique-data",
    "href": "index.html#how-does-wikidata-provide-unique-data",
    "title": "General purpose",
    "section": "How does Wikidata provide unique data",
    "text": "How does Wikidata provide unique data\nThis study demonstrates the possibility to list and collect information on flood events on a large temporal and spatial scale through Wikidata, Wikimedia and Wikipedia projects. Although these data exhibit some heterogeneity (Ruprechter, Burghardt, and Helic 2023) due to economic and digital inequities, being able to rely on a preexistent, rich global dataset spanning a large time period is still a priceless asset in studying floods, and could be a first step to better-quality curated datasets. Besides, institutional global data sources are not immune to spatial heterogeneities due to scarcity of research activity, linguistic barriers, varying degrees of public investment in disaster management, and other sources of environmental, political and social inequities."
  },
  {
    "objectID": "join_data.html",
    "href": "join_data.html",
    "title": "join",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nwd_events=readRDS(\"data/wd_events.RDS\")\nwd_full=readRDS(\"data/wd_full.RDS\")"
  },
  {
    "objectID": "join_data.html#data-from-the-dartmouth-flood-observatory",
    "href": "join_data.html#data-from-the-dartmouth-flood-observatory",
    "title": "join",
    "section": "Data from the Dartmouth Flood Observatory",
    "text": "Data from the Dartmouth Flood Observatory\n\n\nCode\navdate=function(date1,date2){\n  date1=as.numeric(date1)\n  date2=as.numeric(date2)\n  result=as.Date(mean(c(date1,date2)))\n  return(result)\n}\n\n\n\n\nCode\ndfo_raw &lt;- readr::read_csv(\"data/FloodArchive.csv\", \n    locale = locale(decimal_mark = \",\"))\ncolnames(dfo_raw)=c(\"index\",\"GlideNumber\",\"dfo_country\",\"dfo_other_country\",\n           \"dfo_centroid_x\",\"dfo_centroid_y\",\"area\",\"dfo_began\",\"dfo_ended\",\n           \"validation\",\"dfo_dead\",\"displaced\",\"maincause\",\"severity\")\ndfo_raw=dfo_raw %&gt;% \n  mutate(start=lubridate::dmy(dfo_began),\n         end=lubridate::dmy(dfo_ended)) %&gt;% \n  mutate(dfo_other_country=case_when(is.na(dfo_other_country)~\"\",\n                                     dfo_other_country==0~\"\",\n                                     TRUE~dfo_other_country)) %&gt;% \n  mutate(flood=as.character(index),\n         flood_label=as.character(index),\n         country_label=paste(dfo_country,\" \",dfo_other_country),\n         deathtoll=dfo_dead,\n         coords=paste0(\"Point(\",dfo_centroid_x,\" \",dfo_centroid_y,\")\"))\ndfo_comp=dfo_raw %&gt;% \n  select(flood,flood_label,country_label,deathtoll, start, end,coords) %&gt;% \n  mutate(date=purrr::map2(start,end,avdate)) %&gt;% \n  tidyr::unnest(date)\n\n\n\n\nCode\ncoords_wd_map=sf::st_coordinates(wd_map) %&gt;%\n  as_tibble() %&gt;%\n  mutate(coords=glue::glue(\"Point({X} {Y})\")) %&gt;%\n  pull(coords)\nwd_comp=wd_map %&gt;%\n  sf::st_drop_geometry() %&gt;% \n  mutate(coords=coords_wd_map) %&gt;% \n  select(flood,flood_label,country_label,deathtoll, date ,start, end,coords,popup) %&gt;% \n  mutate(flood=stringr::str_replace(flood,\"wd:\",\"\"))\n\n\nThis dataset documents 5130 flood events that occurred between 1985-01-01 and 2021-10-09.\n\n\nCode\nNwd_in_range=wd_events %&gt;% \n  filter(year&gt;=1985 & year&lt;=2021) %&gt;% \n  sf::st_drop_geometry() %&gt;%\n  summarise(n=length(unique(flood))) %&gt;% \n  pull(n)\n\n\nBased on the dates of observations for the DFO data base, 417 out of the 814 flood events in our Wikidata base might fall into it."
  },
  {
    "objectID": "join_data.html#basic-stats",
    "href": "join_data.html#basic-stats",
    "title": "join",
    "section": "Basic stats",
    "text": "Basic stats\n\n\nCode\nwd_comp=wd_comp  %&gt;% \n   mutate(source=\"wd\") %&gt;% \n   mutate(flood=paste0(\"wd:\",flood)) %&gt;% \n   sf::st_drop_geometry() %&gt;% \n   filter(date&gt;lubridate::ymd(\"1985-01-01\") & \n          date&lt;lubridate::ymd(\"2021-12-31\")) \ndfo_comp=dfo_comp %&gt;%\n   mutate(source=\"dfo\") %&gt;%\n   mutate(popup=glue::glue(\"&lt;h1&gt;{flood_label}&lt;/h1&gt;\n                            &lt;p&gt;date: {date}&lt;/p&gt;\n                            &lt;p&gt;deathtoll:{deathtoll}&lt;/p&gt;\"))  \ntib=bind_rows(wd_comp,dfo_comp) %&gt;% \n  mutate(date=lubridate::round_date(date,\"month\")) %&gt;% \n   sf::st_as_sf(wkt=\"coords\")\n\n\nBased on the spatial and temporal data in both datasets, we try to find correspondences between the events described in Wikidata and those described in the Dartmouth Flood Observatory.\n\n\nCode\n# tib %&gt;% \n#   sf::st_transform(crs=\"\")\n\nfind_corresponding_flood=function(flood_id,tib){\n  tib_sub=tib %&gt;% filter(flood==flood_id)\n  tib_dist=tib %&gt;% \n    mutate(disttime=abs(tib$date-tib_sub$date),\n           distspace=sf::st_distance(tib,tib_sub)[,1]) %&gt;% \n    filter(flood!=flood_id) %&gt;%  \n    filter(disttime==min(disttime)|distspace==min(distspace)) %&gt;% \n    filter(disttime&lt;60 & distspace&lt;2) %&gt;%\n    select(floodcorr=flood,\n           disttime,\n           distspace,\n           sourcecorr=source,\n           country_corr=country_label,\n           deathtoll_corr=deathtoll) %&gt;% \n    sf::st_drop_geometry()\n  if(nrow(tib_dist)==0){\n    tib_dist=tibble::tibble(floodcorr=NA,\n                            disttime=NA,\n                            distspace=NA,\n                            sourcecorr=NA,\n                            countrycorr=NA,\n                            deathtollcorr=NA)\n  }\n  return(tib_dist)\n}\n\n\n\n\nCode\nif(!file.exists(\"data/tibcorr.RDS\")){\ntibcorr= tib %&gt;% \n  mutate(data=purrr::map(flood,find_corresponding_flood,tib=tib)) %&gt;% \n  tidyr::unnest(data) %&gt;% \n  filter(source==\"wd\" & sourcecorr==\"dfo\")\nsaveRDS(tibcorr,\n        \"data/tibcorr.RDS\")\n}\n\n\n\n\nCode\ntib=sf::st_as_sf(tib,wkt=\"coords\")\ntibcorr=readRDS(\"data/tibcorr.RDS\") %&gt;% \n  sf::st_drop_geometry()\njoined_events=bind_rows(tibble::tibble(id=1:nrow(tibcorr),flood=tibcorr$flood),\n               tibble::tibble(id=1:nrow(tibcorr),flood=tibcorr$floodcorr))\njoined_events=tib %&gt;% \n  left_join(joined_events, by=\"flood\") %&gt;%  \n  select(id,flood) %&gt;% \n  group_by(id) %&gt;% \n  summarise(m =mean(id),do_union=FALSE) %&gt;% \n  sf::st_cast(\"LINESTRING\")\njoined_events=joined_events[1:(nrow(joined_events)-1),]"
  },
  {
    "objectID": "join_data.html#map-comparison",
    "href": "join_data.html#map-comparison",
    "title": "join",
    "section": "Map comparison",
    "text": "Map comparison\n\n\nCode\nlibrary(leaflet) \ntib_comp_map=tib %&gt;%\n  sf::st_as_sf(wkt=\"coords\")\n# Définition d'une échelle colorée \n# (en fonction de date de sortie) \n# Création de la carte \npal=colorFactor(c(\"red\",\"blue\"), domain=c(\"wd\",\"dfo\"))\ncomp_map=leaflet(tib_comp_map)  %&gt;%\n  addProviderTiles(providers$Esri.NatGeoWorldMap) %&gt;% # ajout fond de carte\n  addCircleMarkers(col=~pal(source),\n                   popup =~popup,\n                   radius =~log(deathtoll+2)\n                   )  %&gt;%\n  addPolylines(data=joined_events,color=\"green\")\n\n\n\n\nCode\ncomp_map"
  },
  {
    "objectID": "index.html#wikidata-on-floods",
    "href": "index.html#wikidata-on-floods",
    "title": "General purpose",
    "section": "Wikidata on floods",
    "text": "Wikidata on floods\n\n\nCode\nwd_events=readRDS(\"data/wd_events.RDS\")\nwd_full=readRDS(\"data/wd_full.RDS\")\nNwd=wd_events %&gt;% nrow()\nNaft1900=wd_events %&gt;% filter(year&gt;=1900) %&gt;% nrow()\nNaft2000=wd_events %&gt;% filter(year&gt;=2000) %&gt;% nrow()\nPropaft1900=Naft1900/Nwd\nPropaft2000=Naft2000/Nwd\n\n\nOur Wikidata base documents 814 flood events, 0.7555283% of which occurred after 1900 and 0.5208845% of which occurred after 2000.\n\n\nCode\nwd_events_freq=wd_events %&gt;% \n  mutate(cat_year=cut(year,breaks=c(1000,1200,1400,1600,1800,\n                                    2000,2023),dig.lab=10)) %&gt;% \n  group_by(cat_year) %&gt;% tally()\np1=ggplot(wd_events_freq, aes(x=cat_year,y=n))+\n  geom_col()\np2=ggplot(wd_events %&gt;% filter(year&gt;=2000), aes(x=year))+\n  geom_histogram(breaks=2000:2023)\nfigure &lt;- ggarrange(p1,p2,\n                    labels = c(\"A\", \"B\"),\n                    ncol = 1, nrow = 2)\nfigure\n\n\n\n\n\nFigure 1: Distribution of flood events through time A) all events dated with a year-accuracy B) events dated with a year-accuracy starting in 2000"
  },
  {
    "objectID": "index.html#compare-to-dfo-data",
    "href": "index.html#compare-to-dfo-data",
    "title": "General purpose",
    "section": "Compare to DFO data",
    "text": "Compare to DFO data"
  }
]